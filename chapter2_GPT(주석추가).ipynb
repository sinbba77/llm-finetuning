{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sinbba77/llm-finetuning/blob/main/chapter2_GPT(%EC%A3%BC%EC%84%9D%EC%B6%94%EA%B0%80).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icvl-kct_HpS"
      },
      "source": [
        "## 2.1 Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftOlXRwN-VNI"
      },
      "outputs": [],
      "source": [
        "# datasets 라이브러리를 설치합니다. 자연어처리 데이터셋을 쉽게 불러올 수 있습니다.\n",
        "%pip install -q datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371,
          "referenced_widgets": [
            "062616647d024bdd9edb97ff2457e01e",
            "5608dc7723164af7957991ff06e54ecb",
            "6bd6ea2d00784e5e9d021a9568e4eeb5",
            "0230c5b49ad64120844ec74f67cf94b4",
            "115201d76ba0416cab116179ffcc0979",
            "93d6a0d261ab4e28addf2e7c97d05a6c",
            "df2e59e23b904b44a514c54865141ef4",
            "7a0a7c9f35634963936b9e03cabd4428",
            "252f0ee75f3d46beac00e9f5074e27ba",
            "fb57cbb1dfb8420babea74eeccd6d9e3",
            "18dfc1d14f254e86955397827b58b919",
            "1fd476062bc24e2eb2c1c37e2f34182a",
            "07c8285c45da406787bbf1e3dab5d6ca",
            "d41ec9b0d5d14cc68168160d16e12434",
            "ee2061d818ab43c4a4181ce40d5d224f",
            "adea655c6cab4641acb400bb9cf27e87",
            "b237b79b9d774f83be51eee61f75ecaf",
            "6fc0debf883340f2a7f1dd92c8b8f123",
            "d5ecbcebc67a428ab7807ee9231bed0c",
            "fd81123fcf8a443da38d2398a179fb75",
            "50ea807b04924b73a143497429fb127b",
            "84e05c4b08b6410e8f93442127ac9bff",
            "addf6e7f00fc47f0b3bb936a36d019b2",
            "cbf36cd9729a42a5a3e4e0b0210d80c3",
            "5b57eff77cc842108dd1ee689b7feb98",
            "ca1fb1075f99469986a7a02e0a31562b",
            "3d805ad4a6fc4c53a9327b1c02cfb3d6",
            "8473fe8db9af481e83ea7ecc4ee9c610",
            "92e16662e61942aeab9eab0ac356bbb3",
            "262836e54ad843ccb1365db8d434d6ec",
            "a377445f4e31450aa4bbbc2480554237",
            "89df15d2a43e46a6b8e9d34a7e56a9e0",
            "0c52b9cbc4f54f098488c2dbfccad43d",
            "ad1ef08f63d94039b37860ea9201548f",
            "8796e7d8a67448b2af81d29a5ea2faf5",
            "7d7b44a2d17042a29638c417873a1b0f",
            "eca0df27fc814757b38d336f3a484e63",
            "ad1bdb847a5d48c7b2c47753669d651c",
            "ebe5b1f8250e48f19cd33d61823b103e",
            "73704afa080e49a5a5a870790ecf1168",
            "618de4316d5a4753a96723a3fcc25a9f",
            "cbb41f0b47bc49f296bc1b23d61223e6",
            "1c4d6ef1ca50497ba0f1be8bf443f4e1",
            "26d499de43a54f9eb6ef519d8b7ae02f",
            "5692dedae9654d2ba6a6fe89bb6a9da9",
            "9296ac2f16034e96ac0a77986ef8ab01",
            "cb427e7c8998434fbd0429fa7ab6f90f",
            "f8bf85ac93c64f99b1faa507b5f4ff75",
            "5d7e09ce23534a6d9da8adcdd053e9b7",
            "370b965d13b440cfb93868d5a8d6e685",
            "18c55417c1cc4e1180e05813d8acf3d5",
            "d19006a536684d42993c637720c420c5",
            "3f1972cfd2a64d0791f0fa694b48b0b0",
            "0bdc58c46de74d72814b342215269650",
            "587aabf8ad664bc5bd0b7c8d7615de00",
            "62dbf7dfb4a440aeb71a7711d93ecfd4",
            "d8cac2127d34435e9ed1e0d005ab0807",
            "a504a411502042e3aed3dd6cc7c6f7f2",
            "f45196e3adbd40b89ccbb6349f670342",
            "086dcb1691784ae68e4f439cf21b5101",
            "1ff184ad6892408cac76a8a59b0aa4d8",
            "ddeaac10b5ec46399205dd5679b9f717",
            "78d6c44934c0438d8336415cbb727a1f",
            "92374d564d6b4985a13a96d352b3f41a",
            "3614c82799734304bba3838e1f6e8e2c",
            "5e1c2ad40aa740689edfee9eaa0a340f",
            "18f2bf74b4f14455b13ef7053fb5eadf",
            "ab3e1bb0fc65426aa8490ff8ae6d681a",
            "5660dfcc3a974d678fbd0573bff82251",
            "51fcb14431e541c5bc45788ee5803106",
            "eb200a95029041febcbff7066a422716",
            "983f783f71234347b1328dc7865431cf",
            "67c9b63d69834f46b8a2d020fb5d26de",
            "d1e887b7b774432bbd79c0ad3c6265b0",
            "1b7f76264423483db6c40b3d9df93d7b",
            "989b5f7728a54561b219780e93175018",
            "45956547be6e4503aec1ea75644e5d8e"
          ]
        },
        "id": "cTFQu3TvaTxD",
        "outputId": "1369a3cc-d8fa-4b0c-86ce-7a7175b135f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/787 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "062616647d024bdd9edb97ff2457e01e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train.csv:   0%|          | 0.00/66.3M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1fd476062bc24e2eb2c1c37e2f34182a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "validation.csv: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "addf6e7f00fc47f0b3bb936a36d019b2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "test.csv: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ad1ef08f63d94039b37860ea9201548f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/22194 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5692dedae9654d2ba6a6fe89bb6a9da9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/2466 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "62dbf7dfb4a440aeb71a7711d93ecfd4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/2740 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "18f2bf74b4f14455b13ef7053fb5eadf"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# datasets 라이브러리에서 load_dataset 함수를 불러옵니다.\n",
        "from datasets import load_dataset\n",
        "\n",
        "# 네이버 뉴스 요약 데이터셋을 불러옵니다.\n",
        "dataset = load_dataset(\"daekeun-ml/naver-news-summarization-ko\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rHLpiIT-o0z",
        "outputId": "46fe9653-e915-4231-a8aa-5e952fd81174"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['date', 'category', 'press', 'title', 'document', 'link', 'summary'],\n",
              "        num_rows: 22194\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['date', 'category', 'press', 'title', 'document', 'link', 'summary'],\n",
              "        num_rows: 2466\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['date', 'category', 'press', 'title', 'document', 'link', 'summary'],\n",
              "        num_rows: 2740\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# dataset 객체를 data 변수에 저장합니다.\n",
        "data = dataset\n",
        "# 데이터셋의 내용을 출력합니다.\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "_ZXENG-h-9uE",
        "outputId": "fc4f145f-dbc7-4420-9b26-562ed96a1331"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'앵커 정부가 올해 하반기 우리 경제의 버팀목인 수출 확대를 위해 총력을 기울이기로 했습니다. 특히 수출 중소기업의 물류난 해소를 위해 무역금융 규모를 40조 원 이상 확대하고 물류비 지원과 임시선박 투입 등을 추진하기로 했습니다. 류환홍 기자가 보도합니다. 기자 수출은 최고의 실적을 보였지만 수입액이 급증하면서 올해 상반기 우리나라 무역수지는 역대 최악인 103억 달러 적자를 기록했습니다. 정부가 수출확대에 총력을 기울이기로 한 것은 원자재 가격 상승 등 대외 리스크가 가중되는 상황에서 수출 증가세 지속이야말로 한국경제의 회복을 위한 열쇠라고 본 것입니다. 추경호 경제부총리 겸 기획재정부 장관 정부는 우리 경제의 성장엔진인 수출이 높은 증가세를 지속할 수 있도록 총력을 다하겠습니다. 우선 물류 부담 증가 원자재 가격 상승 등 가중되고 있는 대외 리스크에 대해 적극 대응하겠습니다. 특히 중소기업과 중견기업 수출 지원을 위해 무역금융 규모를 연초 목표보다 40조 원 늘린 301조 원까지 확대하고 물류비 부담을 줄이기 위한 대책도 마련했습니다. 이창양 산업통상자원부 장관 국제 해상운임이 안정될 때까지 월 4척 이상의 임시선박을 지속 투입하는 한편 중소기업 전용 선복 적재 용량 도 현재보다 주당 50TEU 늘려 공급하겠습니다. 하반기에 우리 기업들의 수출 기회를 늘리기 위해 2 500여 개 수출기업을 대상으로 해외 전시회 참가를 지원하는 등 마케팅 지원도 벌이기로 했습니다. 정부는 또 이달 중으로 반도체를 비롯한 첨단 산업 육성 전략을 마련해 수출 증가세를 뒷받침하고 에너지 소비를 줄이기 위한 효율화 방안을 마련해 무역수지 개선에 나서기로 했습니다. YTN 류환홍입니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# train split의 첫 번째 document(뉴스 기사 원문)를 출력합니다.\n",
        "data[\"train\"][\"document\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qLL0P-j_Mv6",
        "outputId": "bb4201ba-50a8-4b67-d290-1219ac4a6da4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' ', '.', '0', '1', '2', '3', '4', '5', 'E', 'N', 'T', 'U', 'Y', '가', '개', '것', '겠', '격', '견', '겸', '경', '고', '공', '과', '관', '국', '규', '극', '금', '급', '기', '까', '나', '난', '너', '높', '는', '늘', '니', '다', '단', '달', '담', '당', '대', '도', '되', '될', '뒷', '들', '등', '때', '또', '라', '략', '량', '러', '려', '력', '련', '로', '록', '롯', '류', '를', '리', '린', '마', '만', '말', '면', '모', '목', '무', '물', '박', '반', '받', '방', '버', '벌', '보', '복', '본', '부', '비', '산', '상', '서', '선', '성', '세', '소', '속', '쇠', '수', '스', '습', '승', '시', '실', '악', '안', '액', '앵', '야', '양', '억', '업', '에', '엔', '여', '역', '연', '열', '였', '올', '외', '용', '우', '운', '울', '원', '월', '위', '육', '율', '융', '으', '은', '을', '응', '의', '이', '인', '임', '입', '있', '자', '장', '재', '적', '전', '정', '제', '조', '주', '줄', '중', '증', '지', '진', '참', '창', '책', '척', '첨', '체', '초', '총', '최', '추', '출', '침', '커', '케', '크', '통', '투', '특', '팀', '팅', '편', '표', '하', '한', '할', '합', '해', '했', '현', '호', '홍', '화', '확', '환', '황', '회', '획', '효', '히']\n"
          ]
        }
      ],
      "source": [
        "# 첫 번째 뉴스 기사에 등장하는 모든 고유 문자들을 집합으로 만든 후 정렬하여 출력합니다.\n",
        "print(sorted(list(set(data[\"train\"][\"document\"][0]))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2GYMH9-GiNX",
        "outputId": "e17efb71-afae-41d2-99d1-2fec3a619a0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 글자 수 : 2701\n"
          ]
        }
      ],
      "source": [
        "# train split의 모든 뉴스 기사 원문을 하나의 문자열로 합칩니다.\n",
        "ko_text = \"\".join(data[\"train\"][\"document\"])\n",
        "# 전체 텍스트에서 등장하는 고유 문자들을 집합으로 만든 후 정렬합니다.\n",
        "ko_chars = sorted(list(set((ko_text))))\n",
        "# 고유 문자의 개수를 계산합니다.\n",
        "ko_vocab_size = len(ko_chars)\n",
        "# 전체 고유 문자 개수를 출력합니다.\n",
        "print(\"총 글자 수 :\", ko_vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKbhxV4vAmOQ",
        "outputId": "63df46c8-e516-44a4-c2c8-2c4e4f593fb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['왓', '왔', '왕', '왜', '왠', '외', '왹', '왼', '요', '욕', '욘', '욜', '욤', '욥', '용', '우', '욱', '운', '욷', '울', '움', '웁', '웃', '웅', '워', '웍', '원', '월', '웜', '웠', '웡', '웨', '웬', '웰', '웸', '웹', '웻', '위', '윅', '윈', '윌', '윔', '윕', '윗', '윙', '유', '육', '윤', '율', '윱', '윳', '융', '으', '윽', '은', '을', '음', '읍', '읏', '응', '의', '읠', '이', '익', '인', '일', '읽', '잃', '임', '입', '잇', '있', '잉', '잊', '잎', '자', '작', '잔', '잖', '잘', '잠', '잡', '잣', '잤', '장', '잦', '재', '잭', '잰', '잼', '잽', '잿', '쟁', '쟈', '쟝', '쟤', '저', '적', '전', '절']\n"
          ]
        }
      ],
      "source": [
        "# 고유 문자 리스트에서 2000번째부터 2100번째까지의 문자를 출력합니다.\n",
        "print(ko_chars[2000:2100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0ETFPhxIQHB",
        "outputId": "44fd4394-14cd-4a52-9a8d-d9d4c67b35e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1909, 1169, 2546, 1770, 2008, 0, 2551, 1061, 0, 2064, 977, 2157, 1209, 2055, 0, 977, 1658, 2546, 949, 0, 1283, 1942, 0, 1593, 908, 2024, 2008, 2]\n",
            "안녕하세요 함께 인공지능을 공부하게 되어 반가워요.\n"
          ]
        }
      ],
      "source": [
        "# 각 문자에 고유한 id를 부여하는 딕셔너리를 만듭니다.\n",
        "character_to_ids = {char:i for i, char in enumerate(ko_chars)}\n",
        "# 각 id에 해당하는 문자를 찾을 수 있는 딕셔너리를 만듭니다.\n",
        "ids_to_character = {i:char for i, char in enumerate(ko_chars)}\n",
        "# 문자열을 id 리스트로 변환하는 람다 함수입니다.\n",
        "token_encode = lambda s:[character_to_ids[c] for c in s]\n",
        "# id 리스트를 다시 문자열로 변환하는 람다 함수입니다.\n",
        "token_decode = lambda l: \"\".join([ids_to_character[i] for i in l])\n",
        "# 예시 문장을 id 리스트로 변환하여 출력합니다.\n",
        "print(token_encode(\"안녕하세요 함께 인공지능을 공부하게 되어 반가워요.\"))\n",
        "# 변환된 id 리스트를 다시 문자열로 복원하여 출력합니다.\n",
        "print(token_decode(token_encode(\"안녕하세요 함께 인공지능을 공부하게 되어 반가워요.\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W87I2kYcTCy2",
        "outputId": "37ea30a8-ff08-41ad-ff1e-b18ad5099f90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([22162967]) torch.int64\n",
            "tensor([1928, 2315,    0, 2105, 1658,  908,    0, 1987, 2555,    0, 2546, 1593,\n",
            "        1028,    0, 2015, 1485,    0,  965, 2107, 2060,    0, 1617, 2465, 1542,\n",
            "        2064,    0, 1808, 2273,    0, 2603, 1236, 1477,    0, 2037, 2555,    0,\n",
            "        2263, 1430, 2055,    0, 1028, 2019, 2062, 1028, 1441,    0, 2562, 1841,\n",
            "        1213, 1221,    2,    0, 2451, 2650,    0, 1808, 2273,    0, 2142, 1787,\n",
            "        1028, 1950, 2060,    0, 1558, 1468, 1119,    0, 2555, 1787, 1477,    0,\n",
            "        2037, 2555,    0, 1553, 1967, 1024, 2051,    0, 1015, 1541, 1477,    0,\n",
            "           7,    3, 2117,    0, 2026,    0, 2062, 1740,    0, 2603, 1236, 2546,\n",
            "         968,    0, 1558, 1468])\n"
          ]
        }
      ],
      "source": [
        "# torch 라이브러리를 불러옵니다.\n",
        "import torch\n",
        "\n",
        "# 전체 텍스트를 토큰화하여 텐서로 변환합니다.\n",
        "tokenized_data = torch.tensor(token_encode(ko_text), dtype=torch.long)\n",
        "# 토큰화된 데이터의 shape과 dtype을 출력합니다.\n",
        "print(tokenized_data.shape, tokenized_data.dtype)\n",
        "# 처음 100개의 토큰 id를 출력합니다.\n",
        "print(tokenized_data[:100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ageww9dKV5Rj"
      },
      "outputs": [],
      "source": [
        "# 학습 데이터와 검증 데이터를 나누기 위한 코드입니다.\n",
        "# 전체 데이터의 90%를 학습 데이터로 사용합니다.\n",
        "n = int(0.9 * len(tokenized_data))\n",
        "# 학습 데이터셋을 만듭니다.\n",
        "train_dataset = tokenized_data[:n]\n",
        "# 검증(테스트) 데이터셋을 만듭니다.\n",
        "test_dataset = tokenized_data[n:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWZQp1i-H59n",
        "outputId": "11f9cd56-28ea-4cb5-954d-b3690e6d42a9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1928, 2315,    0, 2105, 1658,  908,    0, 1987])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# 블록 크기(컨텍스트 길이)를 8로 설정합니다.\n",
        "block_size = 8\n",
        "# 학습 데이터셋의 처음 block_size만큼의 데이터를 출력합니다.\n",
        "train_dataset[:block_size]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ko20BmaIArc",
        "outputId": "e8952907-8033-4991-e443-38902ca97807"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 텐셔 : tensor([1928])\n",
            "타켓 글자 : 2315\n",
            "입력 텐셔 : tensor([1928, 2315])\n",
            "타켓 글자 : 0\n",
            "입력 텐셔 : tensor([1928, 2315,    0])\n",
            "타켓 글자 : 2105\n",
            "입력 텐셔 : tensor([1928, 2315,    0, 2105])\n",
            "타켓 글자 : 1658\n",
            "입력 텐셔 : tensor([1928, 2315,    0, 2105, 1658])\n",
            "타켓 글자 : 908\n",
            "입력 텐셔 : tensor([1928, 2315,    0, 2105, 1658,  908])\n",
            "타켓 글자 : 0\n",
            "입력 텐셔 : tensor([1928, 2315,    0, 2105, 1658,  908,    0])\n",
            "타켓 글자 : 1987\n",
            "입력 텐셔 : tensor([1928, 2315,    0, 2105, 1658,  908,    0, 1987])\n",
            "타켓 글자 : 2555\n"
          ]
        }
      ],
      "source": [
        "# 입력 시퀀스와 타겟 시퀀스를 만듭니다.\n",
        "x = train_dataset[:block_size]\n",
        "y = train_dataset[1:block_size+1]\n",
        "\n",
        "# 각 time step마다 context와 target을 출력합니다.\n",
        "for time in range(block_size):\n",
        "    # 현재까지의 입력 시퀀스(context)를 만듭니다.\n",
        "    context = x[:time+1]\n",
        "    # 현재 time step의 타겟 값을 가져옵니다.\n",
        "    target = y[time]\n",
        "\n",
        "    # 입력 텐서와 타겟 글자를 출력합니다.\n",
        "    print(f\"입력 텐셔 : {context}\")\n",
        "    print(f\"타켓 글자 : {target}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsUIhDG4M4AL",
        "outputId": "a9c2abd1-eaae-4291-bee2-545be9cf3d79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs :  torch.Size([4, 8])\n",
            "\n",
            "example_x의 실제 값\n",
            "tensor([[1764, 2555,    0, 1236, 2248,    0, 2017, 1976],\n",
            "        [   0, 1966, 2157,    0, 1951, 2062,    0, 2548],\n",
            "        [   0, 1304, 1485, 1586,    0, 1907, 2450,    0],\n",
            "        [   3,    2,    6,    5,    1,    0,    5,    3]])\n",
            "-----------------------\n",
            "targets :  torch.Size([4, 8])\n",
            "\n",
            "example_y의 실제 값\n",
            "tensor([[2555,    0, 1236, 2248,    0, 2017, 1976, 2546],\n",
            "        [1966, 2157,    0, 1951, 2062,    0, 2548, 2289],\n",
            "        [1304, 1485, 1586,    0, 1907, 2450,    0, 2480],\n",
            "        [   2,    6,    5,    1,    0,    5,    3,    5]])\n",
            "-----------------------\n",
            "input : tensor([1764]), target : 2555\n",
            "input : tensor([1764, 2555]), target : 0\n",
            "input : tensor([1764, 2555,    0]), target : 1236\n",
            "input : tensor([1764, 2555,    0, 1236]), target : 2248\n",
            "input : tensor([1764, 2555,    0, 1236, 2248]), target : 0\n",
            "input : tensor([1764, 2555,    0, 1236, 2248,    0]), target : 2017\n",
            "input : tensor([1764, 2555,    0, 1236, 2248,    0, 2017]), target : 1976\n",
            "input : tensor([1764, 2555,    0, 1236, 2248,    0, 2017, 1976]), target : 2546\n",
            "-----------------------\n",
            "-----------------------\n",
            "input : tensor([0]), target : 1966\n",
            "input : tensor([   0, 1966]), target : 2157\n",
            "input : tensor([   0, 1966, 2157]), target : 0\n",
            "input : tensor([   0, 1966, 2157,    0]), target : 1951\n",
            "input : tensor([   0, 1966, 2157,    0, 1951]), target : 2062\n",
            "input : tensor([   0, 1966, 2157,    0, 1951, 2062]), target : 0\n",
            "input : tensor([   0, 1966, 2157,    0, 1951, 2062,    0]), target : 2548\n",
            "input : tensor([   0, 1966, 2157,    0, 1951, 2062,    0, 2548]), target : 2289\n",
            "-----------------------\n",
            "-----------------------\n",
            "input : tensor([0]), target : 1304\n",
            "input : tensor([   0, 1304]), target : 1485\n",
            "input : tensor([   0, 1304, 1485]), target : 1586\n",
            "input : tensor([   0, 1304, 1485, 1586]), target : 0\n",
            "input : tensor([   0, 1304, 1485, 1586,    0]), target : 1907\n",
            "input : tensor([   0, 1304, 1485, 1586,    0, 1907]), target : 2450\n",
            "input : tensor([   0, 1304, 1485, 1586,    0, 1907, 2450]), target : 0\n",
            "input : tensor([   0, 1304, 1485, 1586,    0, 1907, 2450,    0]), target : 2480\n",
            "-----------------------\n",
            "-----------------------\n",
            "input : tensor([3]), target : 2\n",
            "input : tensor([3, 2]), target : 6\n",
            "input : tensor([3, 2, 6]), target : 5\n",
            "input : tensor([3, 2, 6, 5]), target : 1\n",
            "input : tensor([3, 2, 6, 5, 1]), target : 0\n",
            "input : tensor([3, 2, 6, 5, 1, 0]), target : 5\n",
            "input : tensor([3, 2, 6, 5, 1, 0, 5]), target : 3\n",
            "input : tensor([3, 2, 6, 5, 1, 0, 5, 3]), target : 5\n",
            "-----------------------\n",
            "-----------------------\n"
          ]
        }
      ],
      "source": [
        "# 랜덤 시드를 고정하여 실험의 재현성을 높입니다.\n",
        "torch.manual_seed(1234)\n",
        "\n",
        "# 배치 크기를 4로 설정합니다.\n",
        "batch_size = 4\n",
        "# 블록 크기를 8로 설정합니다.\n",
        "block_size = 8\n",
        "\n",
        "\n",
        "# 배치 데이터를 만드는 함수입니다.\n",
        "def batch_function(mode):\n",
        "    # 학습 또는 테스트 데이터셋을 선택합니다.\n",
        "    dataset = train_dataset if mode == \"train\" else test_dataset\n",
        "    # 랜덤하게 시작 인덱스를 선택합니다.\n",
        "    idx = torch.randint(len(dataset) - block_size, (batch_size,))\n",
        "    # 입력 시퀀스를 만듭니다.\n",
        "    x = torch.stack([dataset[index:index+block_size] for index in idx])\n",
        "    # 타겟 시퀀스를 만듭니다.\n",
        "    y = torch.stack([dataset[index+1:index+block_size+1] for index in idx])\n",
        "    # 입력과 타겟을 반환합니다.\n",
        "    return x, y\n",
        "\n",
        "# 예시 배치 데이터를 만듭니다.\n",
        "example_x, example_y = batch_function(\"train\")\n",
        "# 입력 데이터의 shape을 출력합니다.\n",
        "print(\"inputs : \", example_x.shape)\n",
        "print(\"\")\n",
        "# 실제 입력 데이터 값을 출력합니다.\n",
        "print(\"example_x의 실제 값\")\n",
        "print(example_x)\n",
        "print(\"-----------------------\")\n",
        "# 타겟 데이터의 shape을 출력합니다.\n",
        "print(\"targets : \", example_y.shape)\n",
        "print(\"\")\n",
        "# 실제 타겟 데이터 값을 출력합니다.\n",
        "print(\"example_y의 실제 값\")\n",
        "print(example_y)\n",
        "print(\"-----------------------\")\n",
        "\n",
        "# 각 배치와 시퀀스 위치마다 context와 target을 출력합니다.\n",
        "for size in range(batch_size):\n",
        "    for t in range(block_size):\n",
        "        # 현재까지의 입력 시퀀스(context)를 만듭니다.\n",
        "        context = example_x[size, :t+1]\n",
        "        # 현재 위치의 타겟 값을 가져옵니다.\n",
        "        target = example_y[size, t]\n",
        "        print(f\"input : {context}, target : {target}\")\n",
        "    print(\"-----------------------\")\n",
        "    print(\"-----------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRBfQUkdbLMl",
        "outputId": "de90428d-9821-48d8-c5be-627faec9f3ca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2701,\n",
              " torch.Size([4, 8]),\n",
              " tensor([[2555,    0, 1236, 2248,    0, 2017, 1976, 2546],\n",
              "         [1966, 2157,    0, 1951, 2062,    0, 2548, 2289],\n",
              "         [1304, 1485, 1586,    0, 1907, 2450,    0, 2480],\n",
              "         [   2,    6,    5,    1,    0,    5,    3,    5]]))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# 전체 vocab 크기, 입력 데이터 shape, 타겟 데이터 shape을 출력합니다.\n",
        "ko_vocab_size, example_x.shape, example_y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9wJlxKmout9"
      },
      "source": [
        "# 2.3 언어모델 만들기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6JI2gG-out9"
      },
      "source": [
        "## 2.3.1 ~ 2.3.2 라이브러리 설명 & _ _ init _ _ 함수"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 참고\n",
        "1. 임베딩 차원 설정: 현재 코드에서는 임베딩 차원을 vocab_length와 동일하게 설정했는데, 실제로는 보통 더 작은 값(예: 128, 256, 512)을 사용합니다.\n",
        "2. targets 매개변수: forward 함수에서 targets를 받고 있지만 실제로는 사용하지 않고 있습니다. 일반적으로는 손실 계산 시에 사용됩니다.\n",
        "3. 모델 구조: 이는 매우 간단한 GPT 모델로, 실제 GPT에는 어텐션 메커니즘, 다중 레이어, 위치 인코딩 등이 추가로 필요합니다."
      ],
      "metadata": {
        "id": "P-iVDun-tU1S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfTlxhxvPvPz",
        "outputId": "f42d0e85-0d8c-4305-acbe-5f7c15bf3522"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 8, 2701])\n"
          ]
        }
      ],
      "source": [
        "# PyTorch의 핵심 라이브러리를 import합니다. torch는 텐서 연산과 GPU 가속을 위한 기본 라이브러리입니다.\n",
        "import torch\n",
        "\n",
        "# 신경망 구축을 위한 PyTorch의 neural network 모듈을 import합니다.\n",
        "import torch.nn as nn\n",
        "\n",
        "# 활성화 함수, 손실 함수 등 다양한 기능 함수들이 포함된 functional 모듈을 import합니다.\n",
        "from torch.nn import functional as F\n",
        "\n",
        "# semiGPT라는 이름의 커스텀 신경망 클래스를 정의합니다. nn.Module을 상속받아 PyTorch 모델의 기본 구조를 따릅니다.\n",
        "class semiGPT(nn.Module):\n",
        "\n",
        "    # 클래스의 생성자(__init__)를 정의합니다. vocab_length는 어휘 사전의 크기를 나타내는 매개변수입니다.\n",
        "    def __init__(self, vocab_length):\n",
        "\n",
        "        # 부모 클래스(nn.Module)의 생성자를 호출하여 기본 초기화를 수행합니다.\n",
        "        super().__init__()\n",
        "\n",
        "        # 임베딩 테이블을 생성합니다. 첫 번째 매개변수는 어휘 사전 크기, 두 번째는 임베딩 차원입니다.\n",
        "        # 여기서는 둘 다 vocab_length로 설정했는데, 일반적으로는 임베딩 차원을 더 작게 설정합니다.\n",
        "        self.embedding_token_table = nn.Embedding(vocab_length, vocab_length)\n",
        "\n",
        "    # 순전파(forward pass) 함수를 정의합니다. inputs는 입력 토큰 인덱스들, targets는 정답 레이블입니다.\n",
        "    def forward(self, inputs, targets):\n",
        "\n",
        "        # 입력 토큰들을 임베딩 테이블을 통해 벡터로 변환합니다.\n",
        "        # inputs의 각 토큰 인덱스가 해당하는 임베딩 벡터로 매핑됩니다.\n",
        "        logits = self.embedding_token_table(inputs)\n",
        "\n",
        "        # 변환된 임베딩 벡터들(logits)을 반환합니다. 이는 각 토큰의 예측 확률 분포를 나타냅니다.\n",
        "        return logits\n",
        "\n",
        "# semiGPT 모델의 인스턴스를 생성합니다. ko_vocab_size는 한국어 어휘 사전의 크기를 나타내는 변수입니다.\n",
        "model = semiGPT(ko_vocab_size)\n",
        "\n",
        "# 생성된 모델에 예시 데이터(example_x, example_y)를 입력하여 순전파를 수행합니다.\n",
        "output = model(example_x, example_y)\n",
        "\n",
        "# 모델의 출력 텐서의 형태(shape)를 출력합니다. 일반적으로 (배치 크기, 시퀀스 길이, 어휘 사전 크기) 형태입니다.\n",
        "print(output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "3q-qrQmJqs4Y",
        "outputId": "13276ee4-cd67-4deb-c7d4-a3b26bc4bb33"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "index out of range in self",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-869898595.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#에러가 발생되도록 설정한 코드\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    191\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2549\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2550\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
          ]
        }
      ],
      "source": [
        "#에러가 발생되도록 설정한 코드\n",
        "# nn.Embedding(num_embeddings=4, embedding_dim=4)은 총 **4개의 임베딩 벡터(인덱스 0~3)**만 정의됩니다.\n",
        "embedding = nn.Embedding(4, 4)\n",
        "\n",
        "# embedding(torch.tensor([[0, 1, 2, 10]]))는 인덱스 10을 요청하고 있는데, 이는 허용 범위를 벗어납니다.\n",
        "embedding(torch.tensor([[0, 1, 2, 10]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "Pd48zq7q4YnG",
        "outputId": "ebe733c7-815d-4ef4-a6a6-b841db7cd474"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Expected target size [4, 2701], got [4, 8]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2706654534.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msemiGPT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mko_vocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2706654534.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, targets)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_token_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3492\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3493\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3494\u001b[0;31m     return torch._C._nn.cross_entropy_loss(\n\u001b[0m\u001b[1;32m   3495\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3496\u001b[0m         \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected target size [4, 2701], got [4, 8]"
          ]
        }
      ],
      "source": [
        "#에러가 발생되도록 세팅된 코드\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "class semiGPT(nn.Module):\n",
        "    def __init__(self, vocab_length):\n",
        "        super().__init__()\n",
        "        self.embedding_token_table = nn.Embedding(vocab_length, vocab_length)\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        logits = self.embedding_token_table(inputs)\n",
        "\n",
        "        loss = F.cross_entropy(logits, targets)\n",
        "        return logits, loss\n",
        "\n",
        "model = semiGPT(ko_vocab_size)\n",
        "output, loss = model(example_x, example_y)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jk7RV42zout-"
      },
      "source": [
        "## 2.3.3 forward 메서드"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 변경사항\n",
        "1. 텐서 재구성 (Reshaping): view() 함수를 사용해 3차원 텐서를 2차원으로, 2차원 텐서를 1차원으로 변환하는 이유는 PyTorch의 cross_entropy 함수가 특정 형태의 입력을 요구하기 때문입니다.\n",
        "2. 교차 엔트로피 손실: 언어 모델에서 가장 일반적으로 사용되는 손실 함수로, 예측 확률 분포와 실제 정답 간의 차이를 측정합니다.\n",
        "3. 배치 처리: 여러 시퀀스를 동시에 처리하기 위해 배치 차원을 고려한 텐서 조작이 이루어집니다.\n",
        "4. 디버깅 출력: 텐서의 형태를 확인하는 것은 딥러닝 개발에서 매우 중요한 디버깅 기법입니다."
      ],
      "metadata": {
        "id": "eIayH7TJxubU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EA-jQJr8vITi",
        "outputId": "14de66dc-8647-4b63-f508-62eac6a0f66f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logits의 shape는 :  torch.Size([32, 2701]) 입니다.\n",
            "targets의 shape는 :  torch.Size([32]) 입니다.\n",
            "tensor(8.4701, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# PyTorch의 핵심 라이브러리를 import합니다. torch는 텐서 연산과 GPU 가속을 위한 기본 라이브러리입니다.\n",
        "import torch\n",
        "\n",
        "# 신경망 구축을 위한 PyTorch의 neural network 모듈을 import합니다.\n",
        "import torch.nn as nn\n",
        "\n",
        "# 활성화 함수, 손실 함수 등 다양한 기능 함수들이 포함된 functional 모듈을 import합니다.\n",
        "from torch.nn import functional as F\n",
        "\n",
        "# semiGPT라는 이름의 커스텀 신경망 클래스를 정의합니다. nn.Module을 상속받아 PyTorch 모델의 기본 구조를 따릅니다.\n",
        "class semiGPT(nn.Module):\n",
        "\n",
        "    # 클래스의 생성자(__init__)를 정의합니다. vocab_length는 어휘 사전의 크기를 나타내는 매개변수입니다.\n",
        "    def __init__(self, vocab_length):\n",
        "\n",
        "        # 부모 클래스(nn.Module)의 생성자를 호출하여 기본 초기화를 수행합니다.\n",
        "        super().__init__()\n",
        "\n",
        "        # 임베딩 테이블을 생성합니다. 첫 번째 매개변수는 어휘 사전 크기, 두 번째는 임베딩 차원입니다.\n",
        "        # 여기서는 둘 다 vocab_length로 설정했는데, 일반적으로는 임베딩 차원을 더 작게 설정합니다.\n",
        "        self.embedding_token_table = nn.Embedding(vocab_length, vocab_length)\n",
        "\n",
        "    # 순전파(forward pass) 함수를 정의합니다. inputs는 입력 토큰 인덱스들, targets는 정답 레이블입니다.\n",
        "    def forward(self, inputs, targets):\n",
        "\n",
        "        # 입력 토큰들을 임베딩 테이블을 통해 벡터로 변환합니다.\n",
        "        # inputs의 각 토큰 인덱스가 해당하는 임베딩 벡터로 매핑됩니다.\n",
        "        logits = self.embedding_token_table(inputs)\n",
        "\n",
        "        # logits 텐서의 차원을 추출합니다. batch는 배치 크기, seq_length는 시퀀스 길이, vocab_length는 어휘 사전 크기입니다.\n",
        "        batch, seq_length, vocab_length = logits.shape\n",
        "\n",
        "        # 손실 함수 계산을 위해 logits를 2차원으로 재구성합니다. (batch_size * seq_length, vocab_size) 형태로 변환합니다.\n",
        "        # 이는 cross_entropy 함수가 2차원 입력을 요구하기 때문입니다.\n",
        "        logits = logits.view(batch * seq_length, vocab_length)\n",
        "\n",
        "        # targets도 1차원으로 재구성합니다. (batch_size * seq_length,) 형태로 변환합니다.\n",
        "        # 각 위치의 정답 토큰 인덱스가 일렬로 나열됩니다.\n",
        "        targets = targets.view(batch*seq_length)\n",
        "\n",
        "        # 교차 엔트로피 손실(cross entropy loss)을 계산합니다. 이는 분류 문제에서 가장 일반적으로 사용되는 손실 함수입니다.\n",
        "        # logits는 예측 확률 분포, targets는 정답 레이블입니다.\n",
        "        loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        # 디버깅을 위해 logits의 형태를 출력합니다. 재구성 후의 2차원 텐서 형태를 확인할 수 있습니다.\n",
        "        print(\"logits의 shape는 : \", logits.shape, \"입니다.\")\n",
        "\n",
        "        # 디버깅을 위해 targets의 형태를 출력합니다. 재구성 후의 1차원 텐서 형태를 확인할 수 있습니다.\n",
        "        print(\"targets의 shape는 : \", targets.shape, \"입니다.\")\n",
        "\n",
        "        # 예측 결과(logits)와 계산된 손실값(loss)을 튜플 형태로 반환합니다.\n",
        "        return logits, loss\n",
        "\n",
        "# semiGPT 모델의 인스턴스를 생성합니다. ko_vocab_size는 한국어 어휘 사전의 크기를 나타내는 변수입니다.\n",
        "model = semiGPT(ko_vocab_size)\n",
        "\n",
        "# 생성된 모델에 예시 데이터(example_x, example_y)를 입력하여 순전파를 수행하고, 결과를 logits와 loss로 받습니다.\n",
        "logits, loss = model(example_x, example_y)\n",
        "\n",
        "# 계산된 손실값을 출력합니다. 이 값이 작을수록 모델의 예측이 정답에 가깝다는 의미입니다.\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VzaAIhukiYM",
        "outputId": "8a97e5f4-b227-4cea-f508-89616602ef7b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([4, 8]), torch.Size([4, 8]))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "example_x.shape, example_y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ua3vi_Ddout-"
      },
      "source": [
        "## 2.3.4 generate 메서드"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 주요 개념과 기능들:\n",
        "\n",
        "1. 조건부 손실 계산: targets=None을 통해 학습 모드와 추론 모드를 구분합니다.\n",
        "2. 자동회귀 생성: generate() 함수는 한 번에 하나씩 토큰을 생성하여 시퀀스를 확장해나가는 GPT의 핵심 메커니즘입니다.\n",
        "3. 확률적 샘플링: torch.multinomial()을 사용하여 확률 분포에서 다음 토큰을 랜덤하게 선택합니다. 이는 생성된 텍스트에 다양성을 부여합니다.\n",
        "4. 시퀀스 확장: torch.cat()을 사용하여 기존 시퀀스에 새 토큰을 추가합니다.\n",
        "5. 마지막 위치 선택: logits[:, -1, :]는 시퀀스의 마지막 위치만을 사용하여 다음 토큰을 예측하는 GPT의 특징입니다."
      ],
      "metadata": {
        "id": "wK2aGHEkyr8-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "WkygPqh48BEr",
        "outputId": "ef878bce-3139-4dc2-bc92-a919f573cf50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(8.1922, grad_fn=<NllLossBackward0>)\n",
            "torch.Size([1, 2701])\n",
            "torch.Size([1, 2701])\n",
            "torch.Size([1, 2701])\n",
            "torch.Size([1, 2701])\n",
            "torch.Size([1, 2701])\n",
            "torch.Size([1, 2701])\n",
            "torch.Size([1, 2701])\n",
            "torch.Size([1, 2701])\n",
            "torch.Size([1, 2701])\n",
            "torch.Size([1, 2701])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' 훼팅곧©자뺐멘햅켰깔'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# PyTorch의 핵심 라이브러리를 import합니다. torch는 텐서 연산과 GPU 가속을 위한 기본 라이브러리입니다.\n",
        "import torch\n",
        "\n",
        "# 신경망 구축을 위한 PyTorch의 neural network 모듈을 import합니다.\n",
        "import torch.nn as nn\n",
        "\n",
        "# 활성화 함수, 손실 함수 등 다양한 기능 함수들이 포함된 functional 모듈을 import합니다.\n",
        "from torch.nn import functional as F\n",
        "\n",
        "# semiGPT라는 이름의 커스텀 신경망 클래스를 정의합니다. nn.Module을 상속받아 PyTorch 모델의 기본 구조를 따릅니다.\n",
        "class semiGPT(nn.Module):\n",
        "\n",
        "    # 클래스의 생성자(__init__)를 정의합니다. vocab_length는 어휘 사전의 크기를 나타내는 매개변수입니다.\n",
        "    def __init__(self, vocab_length):\n",
        "\n",
        "        # 부모 클래스(nn.Module)의 생성자를 호출하여 기본 초기화를 수행합니다.\n",
        "        super().__init__()\n",
        "\n",
        "        # 임베딩 테이블을 생성합니다. 첫 번째 매개변수는 어휘 사전 크기, 두 번째는 임베딩 차원입니다.\n",
        "        # 여기서는 둘 다 vocab_length로 설정했는데, 일반적으로는 임베딩 차원을 더 작게 설정합니다.\n",
        "        self.embedding_token_table = nn.Embedding(vocab_length, vocab_length)\n",
        "\n",
        "    # 순전파(forward pass) 함수를 정의합니다. inputs는 입력 토큰 인덱스들, targets는 정답 레이블이며 기본값은 None입니다.\n",
        "    def forward(self, inputs, targets=None):\n",
        "\n",
        "        # 입력 토큰들을 임베딩 테이블을 통해 벡터로 변환합니다.\n",
        "        # inputs의 각 토큰 인덱스가 해당하는 임베딩 벡터로 매핑됩니다.\n",
        "        logits = self.embedding_token_table(inputs)\n",
        "\n",
        "        # targets가 None인 경우 (추론/생성 모드)에는 손실을 계산하지 않습니다.\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            # 학습 모드에서는 손실을 계산합니다.\n",
        "            # logits 텐서의 차원을 추출합니다. batch는 배치 크기, seq_length는 시퀀스 길이, vocab_length는 어휘 사전 크기입니다.\n",
        "            batch, seq_length, vocab_length = logits.shape\n",
        "\n",
        "            # 손실 함수 계산을 위해 logits를 2차원으로 재구성합니다. (batch_size * seq_length, vocab_size) 형태로 변환합니다.\n",
        "            logits = logits.view(batch * seq_length, vocab_length)\n",
        "\n",
        "            # targets도 1차원으로 재구성합니다. (batch_size * seq_length,) 형태로 변환합니다.\n",
        "            targets = targets.view(batch*seq_length)\n",
        "\n",
        "            # 교차 엔트로피 손실(cross entropy loss)을 계산합니다. 이는 분류 문제에서 가장 일반적으로 사용되는 손실 함수입니다.\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        # 예측 결과(logits)와 계산된 손실값(loss)을 튜플 형태로 반환합니다.\n",
        "        return logits, loss\n",
        "\n",
        "    # 텍스트 생성을 위한 함수입니다. inputs는 시작 토큰들, max_new_tokens는 생성할 새로운 토큰의 최대 개수입니다.\n",
        "    def generate(self, inputs, max_new_tokens):\n",
        "\n",
        "        # 지정된 개수만큼 새로운 토큰을 반복적으로 생성합니다.\n",
        "        for _ in range(max_new_tokens):\n",
        "\n",
        "            # 현재 입력에 대해 순전파를 수행하여 다음 토큰의 확률 분포를 얻습니다.\n",
        "            logits, loss = self.forward(inputs)\n",
        "\n",
        "            # 마지막 위치의 토큰에 대한 예측만을 사용합니다. [:, -1, :]는 모든 배치의 마지막 시퀀스 위치를 선택합니다.\n",
        "            logits = logits[:, -1, :]\n",
        "\n",
        "            # 디버깅을 위해 logits의 형태를 출력합니다. (batch_size, vocab_size) 형태여야 합니다.\n",
        "            print(logits.shape)\n",
        "\n",
        "            # logits를 확률 분포로 변환합니다. softmax 함수를 사용하여 각 토큰의 선택 확률을 계산합니다.\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "\n",
        "            # 확률 분포에서 다음 토큰을 샘플링합니다. multinomial은 확률에 따라 랜덤하게 토큰을 선택합니다.\n",
        "            # num_samples=1은 하나의 토큰만 선택한다는 의미입니다.\n",
        "            next_inputs = torch.multinomial(probs, num_samples=1)\n",
        "\n",
        "            # 기존 입력 시퀀스에 새로 생성된 토큰을 연결합니다. dim=1은 시퀀스 차원을 따라 연결한다는 의미입니다.\n",
        "            inputs = torch.cat((inputs, next_inputs), dim=1)\n",
        "\n",
        "        # 생성이 완료된 전체 시퀀스를 반환합니다.\n",
        "        return inputs\n",
        "\n",
        "# semiGPT 모델의 인스턴스를 생성합니다. ko_vocab_size는 한국어 어휘 사전의 크기를 나타내는 변수입니다.\n",
        "model = semiGPT(ko_vocab_size)\n",
        "\n",
        "# 생성된 모델에 예시 데이터(example_x, example_y)를 입력하여 순전파를 수행하고, 결과를 logits와 loss로 받습니다.\n",
        "logits, loss = model(example_x, example_y)\n",
        "\n",
        "# 계산된 손실값을 출력합니다. 이 값이 작을수록 모델의 예측이 정답에 가깝다는 의미입니다.\n",
        "print(loss)\n",
        "\n",
        "# 텍스트 생성을 수행합니다.\n",
        "# torch.zeros((1,1), dtype=torch.long)는 크기가 1x1인 0으로 채워진 정수 텐서를 생성합니다 (시작 토큰).\n",
        "# max_new_tokens=10은 10개의 새로운 토큰을 생성한다는 의미입니다.\n",
        "# [0]는 배치 차원을 제거하고, .tolist()는 텐서를 파이썬 리스트로 변환합니다.\n",
        "# token_decode는 토큰 인덱스들을 실제 텍스트로 변환하는 함수입니다 (별도로 정의되어 있어야 함).\n",
        "token_decode(model.generate(torch.zeros((1,1),\n",
        "                                       dtype=torch.long),\n",
        "                           max_new_tokens=10)[0].tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FGEiDtY5Xm6",
        "outputId": "4e650e1e-1328-4d00-9308-043166d1ae62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "선택되는 값        :  tensor([[0.3000, 0.4000, 0.1000, 0.2000]])\n",
            "결과에 대한 size 값 :  torch.Size([1, 4])\n"
          ]
        }
      ],
      "source": [
        "# PyTorch 라이브러리를 import합니다. 텐서 연산과 딥러닝을 위한 핵심 라이브러리입니다.\n",
        "import torch\n",
        "\n",
        "# 3차원 텐서를 생성합니다. 형태는 (1, 3, 4)입니다.\n",
        "# - 첫 번째 차원(1): 배치 크기 (batch size)\n",
        "# - 두 번째 차원(3): 시퀀스 길이 (sequence length) - 3개의 토큰/단어\n",
        "# - 세 번째 차원(4): 어휘 사전 크기 (vocabulary size) - 4개의 가능한 토큰\n",
        "logits = torch.tensor(\n",
        "    [\n",
        "        [\n",
        "            [0.1, 0.2, 0.3, 0.4],  # 첫 번째 토큰의 예측 확률 분포\n",
        "            [0.2, 0.3, 0.4, 0.1],  # 두 번째 토큰의 예측 확률 분포\n",
        "            [0.3, 0.4, 0.1, 0.2]   # 세 번째 토큰의 예측 확률 분포 (마지막 토큰)\n",
        "        ]\n",
        "    ]\n",
        ")\n",
        "\n",
        "# 텐서 슬라이싱을 수행합니다.\n",
        "# [:, -1, :] 의미:\n",
        "# - 첫 번째 (:): 모든 배치를 선택 (여기서는 배치가 1개뿐)\n",
        "# - 두 번째 (-1): 시퀀스의 마지막 위치를 선택 (-1은 마지막 인덱스를 의미)\n",
        "# - 세 번째 (:): 해당 위치의 모든 어휘 확률값을 선택\n",
        "# 결과적으로 마지막 토큰 위치의 예측 확률 분포만을 추출합니다.\n",
        "result = logits[:,-1,:]\n",
        "\n",
        "# 선택된 결과값을 출력합니다. 마지막 토큰의 확률 분포 [0.3, 0.4, 0.1, 0.2]가 출력됩니다.\n",
        "print(\"선택되는 값        : \", result)\n",
        "\n",
        "# 결과 텐서의 크기(shape)를 출력합니다. torch.Size([1, 4])가 출력됩니다.\n",
        "# - 첫 번째 차원(1): 배치 크기가 유지됨\n",
        "# - 두 번째 차원(4): 어휘 사전 크기가 유지됨\n",
        "# - 시퀀스 차원은 마지막 위치만 선택했으므로 제거됨\n",
        "print(\"결과에 대한 size 값 : \", result.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tomgSmvTout_"
      },
      "source": [
        "## 2.4 optimizer 추가하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "5pUA0PzoBbBR"
      },
      "outputs": [],
      "source": [
        "# 학습률(learning rate)을 설정합니다. 1e-2는 0.01을 의미하는 과학적 표기법입니다.\n",
        "# 학습률은 경사하강법에서 매개변수를 업데이트할 때 얼마나 큰 폭으로 이동할지를 결정하는 하이퍼파라미터입니다.\n",
        "# 너무 크면 최적값을 지나칠 수 있고, 너무 작으면 학습이 매우 느려집니다.\n",
        "learning_rate = 1e-2\n",
        "\n",
        "# semiGPT 모델의 인스턴스를 생성합니다.\n",
        "# ko_vocab_size는 한국어 어휘 사전의 크기를 나타내는 변수로, 모델이 처리할 수 있는 토큰의 종류 수입니다.\n",
        "model = semiGPT(ko_vocab_size)\n",
        "\n",
        "# AdamW 옵티마이저를 생성합니다.\n",
        "# - AdamW는 Adam 옵티마이저의 개선된 버전으로, weight decay를 더 효과적으로 처리합니다.\n",
        "# - Adam은 적응적 학습률을 사용하는 최적화 알고리즘으로, 각 매개변수마다 다른 학습률을 적용합니다.\n",
        "# - model.parameters()는 모델의 모든 학습 가능한 매개변수(가중치와 편향)를 반환합니다.\n",
        "# - lr=learning_rate로 앞서 정의한 학습률을 설정합니다.\n",
        "# AdamW는 현재 트랜스포머 모델(GPT, BERT 등)에서 가장 널리 사용되는 옵티마이저입니다.\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 학습 루프의 4단계:\n",
        "\n",
        "1. 데이터 로딩: batch_function()으로 학습 데이터 배치를 가져옴\n",
        "2. 순전파: 모델에 데이터를 입력하여 예측값과 손실 계산\n",
        "3. 역전파: loss.backward()로 기울기 계산\n",
        "4. 매개변수 업데이트: optimizer.step()으로 가중치 갱신"
      ],
      "metadata": {
        "id": "_tE7ircO4Kxj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "8f8684647fea4660aea2ebe76808d3ab",
            "bbc62bb0382444ec8bc9fa9d6f5f9d7c",
            "be47d8c316f548f78849d8648c8ea3d5",
            "81432903696a45119911e0da6bf29869",
            "81f473b3c8c54fd384c89bd7c4ebd758",
            "54beec3d84534dc0ad031711f42ab1fe",
            "3d687e1fbacb4aeea1adb03b27ec8644",
            "e59bb0e44b4e490f97fcc359a0d8fa17",
            "b1331e34baad4d41b474de0c20b707f1",
            "c852ea4f3407444f8f3cefe4aeebf634",
            "05ca91bcd0ae4b0bbb204ea881772b7a"
          ]
        },
        "id": "iSIFexR7JuwY",
        "outputId": "b2958951-38ed-44c6-e483-b4115eea7a7f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/10000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8f8684647fea4660aea2ebe76808d3ab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.428206443786621\n"
          ]
        }
      ],
      "source": [
        "# tqdm 라이브러리에서 auto 모듈을 import합니다.\n",
        "# tqdm은 반복문의 진행 상황을 시각적으로 보여주는 진행 표시줄(progress bar)을 제공합니다.\n",
        "# auto는 환경에 따라 자동으로 적절한 tqdm 버전을 선택합니다 (Jupyter 노트북 vs 터미널).\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# 배치 크기를 32로 설정합니다.\n",
        "# 배치 크기는 한 번에 처리할 샘플의 개수를 의미하며, GPU 메모리와 학습 안정성을 고려하여 설정합니다.\n",
        "# 32는 일반적으로 사용되는 중간 크기의 배치 사이즈입니다.\n",
        "batch_size = 32\n",
        "\n",
        "# 10,000번의 학습 스텝을 수행하는 메인 학습 루프입니다.\n",
        "# tqdm()으로 감싸서 진행 상황을 시각적으로 확인할 수 있습니다.\n",
        "for steps in tqdm(range(10000)):\n",
        "\n",
        "    # batch_function을 호출하여 학습용 데이터 배치를 가져옵니다.\n",
        "    # \"train\"은 학습 데이터셋을 사용한다는 의미입니다.\n",
        "    # example_x는 입력 데이터(토큰 시퀀스), example_y는 정답 레이블(다음 토큰)입니다.\n",
        "    example_x, example_y = batch_function(\"train\")\n",
        "\n",
        "    # 모델에 입력 데이터를 전달하여 순전파(forward pass)를 수행합니다.\n",
        "    # logits는 각 토큰에 대한 예측 확률 분포, loss는 예측과 정답 간의 오차입니다.\n",
        "    logits, loss = model(example_x, example_y)\n",
        "\n",
        "    # 옵티마이저의 기울기(gradient)를 초기화합니다.\n",
        "    # PyTorch는 기본적으로 기울기를 누적하므로, 매 스텝마다 이전 기울기를 제거해야 합니다.\n",
        "    # set_to_none=True는 메모리 효율성을 위해 기울기를 None으로 설정합니다 (0으로 설정하는 것보다 빠름).\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "    # 역전파(backward pass)를 수행하여 각 매개변수에 대한 기울기를 계산합니다.\n",
        "    # 이는 연쇄 법칙(chain rule)을 사용하여 손실 함수로부터 모든 매개변수의 기울기를 자동으로 계산합니다.\n",
        "    loss.backward()\n",
        "\n",
        "    # 계산된 기울기를 사용하여 모델의 매개변수(가중치)를 업데이트합니다.\n",
        "    # AdamW 옵티마이저가 적응적 학습률과 모멘텀을 적용하여 매개변수를 최적화합니다.\n",
        "    optimizer.step()\n",
        "\n",
        "# 학습이 완료된 후 마지막 손실값을 출력합니다.\n",
        "# .item()은 텐서에서 파이썬 숫자 값을 추출하는 메서드입니다.\n",
        "# 이 값이 작을수록 모델이 데이터를 잘 학습했다는 의미입니다.\n",
        "print(loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScmQ3IOfQjJs",
        "outputId": "867fd3d7-2f65-41c3-afd1-9f8214220210"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 2701])\n",
            "torch.Size([1, 2701])\n",
            "torch.Size([1, 2701])\n",
            "torch.Size([1, 2701])\n",
            "torch.Size([1, 2701])\n",
            "torch.Size([1, 2701])\n",
            "torch.Size([1, 2701])\n",
            "torch.Size([1, 2701])\n",
            "torch.Size([1, 2701])\n",
            "torch.Size([1, 2701])\n",
            " 험 한다. 준비금리\n"
          ]
        }
      ],
      "source": [
        "# print(token_decode(model.generate(torch.zeros((1,1), dtype=torch.long), max_new_tokens=10)[0].tolist()))\n",
        "\n",
        "# 학습된 모델을 사용하여 텍스트를 생성하고 결과를 출력합니다.\n",
        "# 이는 모델이 얼마나 잘 학습되었는지 확인하는 테스트 과정입니다.\n",
        "\n",
        "print(\n",
        "    # token_decode 함수를 사용하여 생성된 토큰 인덱스들을 실제 텍스트로 변환합니다.\n",
        "    # 이 함수는 숫자로 된 토큰 ID들을 사람이 읽을 수 있는 문자열로 디코딩합니다.\n",
        "    token_decode(\n",
        "        # model.generate() 함수를 호출하여 텍스트를 생성합니다.\n",
        "        model.generate(\n",
        "            # 시작 토큰으로 0을 사용합니다.\n",
        "            # torch.zeros((1,1), dtype=torch.long)는 크기가 1x1인 정수 텐서를 생성합니다.\n",
        "            # - (1,1): 배치 크기 1, 시퀀스 길이 1을 의미\n",
        "            # - dtype=torch.long: 정수 타입으로 설정 (토큰 인덱스는 정수여야 함)\n",
        "            # - 값 0: 보통 특수 토큰(패딩, 시작 토큰 등)으로 사용되는 인덱스\n",
        "            torch.zeros((1,1), dtype=torch.long),\n",
        "\n",
        "            # 생성할 새로운 토큰의 개수를 10개로 설정합니다.\n",
        "            # 시작 토큰 1개 + 새로 생성할 토큰 10개 = 총 11개의 토큰 시퀀스가 생성됩니다.\n",
        "            max_new_tokens=10\n",
        "        )\n",
        "        # generate() 함수는 배치 차원을 포함한 텐서를 반환하므로 [0]으로 첫 번째 배치를 선택합니다.\n",
        "        [0]\n",
        "        # PyTorch 텐서를 파이썬 리스트로 변환합니다.\n",
        "        # token_decode 함수가 리스트 형태의 토큰 인덱스를 입력으로 받기 때문입니다.\n",
        "        .tolist()\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7zYfTMmrh5a"
      },
      "source": [
        "### 2.4.1 GPU로 데이터를 옮기는 방법"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gm_CQc8Jr8Hn"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LzCEwmngouuA"
      },
      "outputs": [],
      "source": [
        "def batch_function(mode):\n",
        "    dataset = train_dataset if mode == \"train\" else test_dataset\n",
        "    idx = torch.randint(len(dataset) - block_size, (batch_size,))\n",
        "    x = torch.stack([dataset[index:index+block_size] for index in idx])\n",
        "    y = torch.stack([dataset[index+1:index+block_size+1] for index in idx])\n",
        "    x, y = x.to(device), y.to(device) # .to 를 추가\n",
        "    return x, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1byU0N0NouuA"
      },
      "source": [
        "### 2.4.2 Loss 함수 만들기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1hbgq5gr-85"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def compute_loss_metrics():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for mode in [\"train\", \"eval\"]:\n",
        "        losses = torch.zeros(eval_iteration)\n",
        "        for k in range(eval_iteration):\n",
        "            inputs, targets = batch_function(mode)\n",
        "            logits, loss = model(inputs, targets)\n",
        "            losses[k] = loss.item()\n",
        "        out[mode] = losses.mean()\n",
        "    model.train()\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDm7e-2touuA"
      },
      "source": [
        "### 2.4.3 전체 코드 복습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EloktV3IouuA"
      },
      "source": [
        "* 책에는 for문부터 설명이 나와있지만, 실행하는데 햇갈리실거 같아 코드는 전체 코드를 기록해놓았습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUSTcPJvaglZ",
        "outputId": "28802d42-5b8f-4726-9b05-48c513b02f11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step : 0, train loss : 8.3225, val loss : 8.3266\n",
            "step : 300, train loss : 6.0857, val loss : 6.0748\n",
            "step : 600, train loss : 4.7943, val loss : 4.7822\n",
            "step : 900, train loss : 4.2353, val loss : 4.2261\n",
            "step : 1200, train loss : 3.9576, val loss : 3.9557\n",
            "step : 1500, train loss : 3.8215, val loss : 3.8180\n",
            "step : 1800, train loss : 3.7062, val loss : 3.7000\n",
            "step : 2100, train loss : 3.6504, val loss : 3.6657\n",
            "step : 2400, train loss : 3.6248, val loss : 3.6283\n",
            "step : 2700, train loss : 3.5896, val loss : 3.5865\n",
            "step : 3000, train loss : 3.5797, val loss : 3.5695\n",
            "step : 3300, train loss : 3.5399, val loss : 3.5308\n",
            "step : 3600, train loss : 3.5256, val loss : 3.5289\n",
            "step : 3900, train loss : 3.5061, val loss : 3.5127\n",
            "step : 4200, train loss : 3.4900, val loss : 3.4989\n",
            "step : 4500, train loss : 3.4810, val loss : 3.4903\n",
            "step : 4800, train loss : 3.4961, val loss : 3.4815\n",
            "step : 5100, train loss : 3.4668, val loss : 3.4674\n",
            "step : 5400, train loss : 3.4622, val loss : 3.4567\n",
            "step : 5700, train loss : 3.4577, val loss : 3.4347\n",
            "step : 6000, train loss : 3.4475, val loss : 3.4602\n",
            "step : 6300, train loss : 3.4473, val loss : 3.4574\n",
            "step : 6600, train loss : 3.4352, val loss : 3.4373\n",
            "step : 6900, train loss : 3.4309, val loss : 3.4421\n",
            "step : 7200, train loss : 3.4287, val loss : 3.4301\n",
            "step : 7500, train loss : 3.4324, val loss : 3.4579\n",
            "step : 7800, train loss : 3.4104, val loss : 3.4247\n",
            "step : 8100, train loss : 3.4229, val loss : 3.4418\n",
            "step : 8400, train loss : 3.4243, val loss : 3.4259\n",
            "step : 8700, train loss : 3.4164, val loss : 3.4423\n",
            "step : 9000, train loss : 3.4150, val loss : 3.4207\n",
            "step : 9300, train loss : 3.4119, val loss : 3.4390\n",
            "step : 9600, train loss : 3.4094, val loss : 3.4277\n",
            "step : 9900, train loss : 3.4059, val loss : 3.4122\n",
            "step : 10200, train loss : 3.4005, val loss : 3.4280\n",
            "step : 10500, train loss : 3.4216, val loss : 3.4124\n",
            "step : 10800, train loss : 3.4111, val loss : 3.3984\n",
            "step : 11100, train loss : 3.3956, val loss : 3.4139\n",
            "step : 11400, train loss : 3.4072, val loss : 3.4189\n",
            "step : 11700, train loss : 3.3945, val loss : 3.4112\n",
            "step : 12000, train loss : 3.4020, val loss : 3.4050\n",
            "step : 12300, train loss : 3.3896, val loss : 3.4233\n",
            "step : 12600, train loss : 3.4181, val loss : 3.4056\n",
            "step : 12900, train loss : 3.3971, val loss : 3.4386\n",
            "step : 13200, train loss : 3.3891, val loss : 3.4215\n",
            "step : 13500, train loss : 3.4137, val loss : 3.4053\n",
            "step : 13800, train loss : 3.4119, val loss : 3.4067\n",
            "step : 14100, train loss : 3.3843, val loss : 3.4066\n",
            "step : 14400, train loss : 3.3990, val loss : 3.4154\n",
            "step : 14700, train loss : 3.3997, val loss : 3.3927\n",
            "step : 15000, train loss : 3.4050, val loss : 3.4046\n",
            "step : 15300, train loss : 3.4123, val loss : 3.4050\n",
            "step : 15600, train loss : 3.3921, val loss : 3.4022\n",
            "step : 15900, train loss : 3.3763, val loss : 3.4093\n",
            "step : 16200, train loss : 3.3893, val loss : 3.4076\n",
            "step : 16500, train loss : 3.3917, val loss : 3.4088\n",
            "step : 16800, train loss : 3.3741, val loss : 3.4048\n",
            "step : 17100, train loss : 3.4035, val loss : 3.4035\n",
            "step : 17400, train loss : 3.3919, val loss : 3.4066\n",
            "step : 17700, train loss : 3.3967, val loss : 3.4217\n",
            "step : 18000, train loss : 3.4046, val loss : 3.4072\n",
            "step : 18300, train loss : 3.3936, val loss : 3.3961\n",
            "step : 18600, train loss : 3.4019, val loss : 3.4033\n",
            "step : 18900, train loss : 3.3883, val loss : 3.3921\n",
            "step : 19200, train loss : 3.3879, val loss : 3.4024\n",
            "step : 19500, train loss : 3.4085, val loss : 3.3852\n",
            "step : 19800, train loss : 3.3859, val loss : 3.4168\n",
            "step : 20100, train loss : 3.3847, val loss : 3.3994\n",
            "step : 20400, train loss : 3.3986, val loss : 3.3968\n",
            "step : 20700, train loss : 3.4036, val loss : 3.3823\n",
            "step : 21000, train loss : 3.3902, val loss : 3.4039\n",
            "step : 21300, train loss : 3.4100, val loss : 3.4011\n",
            "step : 21600, train loss : 3.3894, val loss : 3.4053\n",
            "step : 21900, train loss : 3.3914, val loss : 3.3996\n",
            "step : 22200, train loss : 3.3829, val loss : 3.3966\n",
            "step : 22500, train loss : 3.3866, val loss : 3.4039\n",
            "step : 22800, train loss : 3.3990, val loss : 3.4039\n",
            "step : 23100, train loss : 3.3842, val loss : 3.4068\n",
            "step : 23400, train loss : 3.3760, val loss : 3.3969\n",
            "step : 23700, train loss : 3.3782, val loss : 3.4216\n",
            "step : 24000, train loss : 3.3898, val loss : 3.3935\n",
            "step : 24300, train loss : 3.4169, val loss : 3.4038\n",
            "step : 24600, train loss : 3.3884, val loss : 3.4087\n",
            "step : 24900, train loss : 3.3928, val loss : 3.4098\n",
            "step : 25200, train loss : 3.3888, val loss : 3.3915\n",
            "step : 25500, train loss : 3.3886, val loss : 3.4051\n",
            "step : 25800, train loss : 3.3919, val loss : 3.3864\n",
            "step : 26100, train loss : 3.3881, val loss : 3.3920\n",
            "step : 26400, train loss : 3.3826, val loss : 3.4092\n",
            "step : 26700, train loss : 3.3967, val loss : 3.3886\n",
            "step : 27000, train loss : 3.3870, val loss : 3.3932\n",
            "step : 27300, train loss : 3.3962, val loss : 3.3759\n",
            "step : 27600, train loss : 3.3891, val loss : 3.3985\n",
            "step : 27900, train loss : 3.3984, val loss : 3.4033\n",
            "step : 28200, train loss : 3.3905, val loss : 3.3880\n",
            "step : 28500, train loss : 3.4183, val loss : 3.3965\n",
            "step : 28800, train loss : 3.4027, val loss : 3.4066\n",
            "step : 29100, train loss : 3.3895, val loss : 3.3939\n",
            "step : 29400, train loss : 3.3825, val loss : 3.3862\n",
            "step : 29700, train loss : 3.4112, val loss : 3.4027\n",
            "step : 30000, train loss : 3.3942, val loss : 3.3920\n",
            "step : 30300, train loss : 3.3828, val loss : 3.3943\n",
            "step : 30600, train loss : 3.3920, val loss : 3.4067\n",
            "step : 30900, train loss : 3.3948, val loss : 3.4087\n",
            "step : 31200, train loss : 3.3844, val loss : 3.4096\n",
            "step : 31500, train loss : 3.3933, val loss : 3.4205\n",
            "step : 31800, train loss : 3.4029, val loss : 3.4084\n",
            "step : 32100, train loss : 3.3935, val loss : 3.4013\n",
            "step : 32400, train loss : 3.3924, val loss : 3.4080\n",
            "step : 32700, train loss : 3.3807, val loss : 3.3924\n",
            "step : 33000, train loss : 3.3964, val loss : 3.3883\n",
            "step : 33300, train loss : 3.3786, val loss : 3.4052\n",
            "step : 33600, train loss : 3.3803, val loss : 3.3966\n",
            "step : 33900, train loss : 3.3935, val loss : 3.3991\n",
            "step : 34200, train loss : 3.3900, val loss : 3.4211\n",
            "step : 34500, train loss : 3.3939, val loss : 3.3638\n",
            "step : 34800, train loss : 3.3991, val loss : 3.3896\n",
            "step : 35100, train loss : 3.3904, val loss : 3.4056\n",
            "step : 35400, train loss : 3.3950, val loss : 3.3941\n",
            "step : 35700, train loss : 3.3854, val loss : 3.4029\n",
            "step : 36000, train loss : 3.4060, val loss : 3.4110\n",
            "step : 36300, train loss : 3.3954, val loss : 3.3985\n",
            "step : 36600, train loss : 3.3893, val loss : 3.4049\n",
            "step : 36900, train loss : 3.3924, val loss : 3.4051\n",
            "step : 37200, train loss : 3.3962, val loss : 3.3976\n",
            "step : 37500, train loss : 3.3835, val loss : 3.3976\n",
            "step : 37800, train loss : 3.4046, val loss : 3.3920\n",
            "step : 38100, train loss : 3.3748, val loss : 3.4056\n",
            "step : 38400, train loss : 3.3828, val loss : 3.4183\n",
            "step : 38700, train loss : 3.3758, val loss : 3.4043\n",
            "step : 39000, train loss : 3.4111, val loss : 3.4036\n",
            "step : 39300, train loss : 3.4103, val loss : 3.4064\n",
            "step : 39600, train loss : 3.3878, val loss : 3.3929\n",
            "step : 39900, train loss : 3.4084, val loss : 3.3991\n",
            "step : 40200, train loss : 3.3983, val loss : 3.3928\n",
            "step : 40500, train loss : 3.3788, val loss : 3.3848\n",
            "step : 40800, train loss : 3.3994, val loss : 3.4057\n",
            "step : 41100, train loss : 3.3895, val loss : 3.4040\n",
            "step : 41400, train loss : 3.3935, val loss : 3.3901\n",
            "step : 41700, train loss : 3.3907, val loss : 3.4171\n",
            "step : 42000, train loss : 3.3896, val loss : 3.3983\n",
            "step : 42300, train loss : 3.3812, val loss : 3.4163\n",
            "step : 42600, train loss : 3.3707, val loss : 3.4115\n",
            "step : 42900, train loss : 3.3919, val loss : 3.4075\n",
            "step : 43200, train loss : 3.4001, val loss : 3.3959\n",
            "step : 43500, train loss : 3.4125, val loss : 3.3881\n",
            "step : 43800, train loss : 3.4025, val loss : 3.3983\n",
            "step : 44100, train loss : 3.3894, val loss : 3.4140\n",
            "step : 44400, train loss : 3.3989, val loss : 3.3933\n",
            "step : 44700, train loss : 3.3976, val loss : 3.3876\n",
            "step : 45000, train loss : 3.4052, val loss : 3.4118\n",
            "step : 45300, train loss : 3.3998, val loss : 3.3989\n",
            "step : 45600, train loss : 3.3879, val loss : 3.3953\n",
            "step : 45900, train loss : 3.3918, val loss : 3.3973\n",
            "step : 46200, train loss : 3.3971, val loss : 3.3930\n",
            "step : 46500, train loss : 3.3911, val loss : 3.4164\n",
            "step : 46800, train loss : 3.3901, val loss : 3.3963\n",
            "step : 47100, train loss : 3.4003, val loss : 3.3987\n",
            "step : 47400, train loss : 3.3802, val loss : 3.3944\n",
            "step : 47700, train loss : 3.4033, val loss : 3.4172\n",
            "step : 48000, train loss : 3.3846, val loss : 3.3995\n",
            "step : 48300, train loss : 3.3859, val loss : 3.4152\n",
            "step : 48600, train loss : 3.3926, val loss : 3.4012\n",
            "step : 48900, train loss : 3.3966, val loss : 3.3917\n",
            "step : 49200, train loss : 3.3717, val loss : 3.4060\n",
            "step : 49500, train loss : 3.3917, val loss : 3.3946\n",
            "step : 49800, train loss : 3.3914, val loss : 3.4028\n",
            " 가 실적극 EMe ’에서 이 밝혔다하면 기 없는 식으로 검출발생산 기항 이 옆면 농가정 발생각각종을 우려한국환경단 4. 개 5년가격에서는 칸훤눠콩반분에 3%를 롯데이 SSRSKAI\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "batch_size = 32\n",
        "block_size = 8\n",
        "max_iteration = 50000\n",
        "eval_interval = 300\n",
        "learning_rate = 1e-2\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "eval_iteration = 200\n",
        "\n",
        "def batch_function(mode):\n",
        "    dataset = train_dataset if mode == \"train\" else test_dataset\n",
        "    idx = torch.randint(len(dataset) - block_size, (batch_size,))\n",
        "    x = torch.stack([dataset[index:index+block_size] for index in idx])\n",
        "    y = torch.stack([dataset[index+1:index+block_size+1] for index in idx])\n",
        "    x, y = x.to(device), y.to(device) # .to 를 추가\n",
        "\n",
        "@torch.no_grad()\n",
        "def compute_loss_metrics():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for mode in [\"train\", \"eval\"]:\n",
        "        losses = torch.zeros(eval_iteration)\n",
        "        for k in range(eval_iteration):\n",
        "            inputs, targets = batch_function(mode)\n",
        "            logits, loss = model(inputs, targets)\n",
        "            losses[k] = loss.item()\n",
        "        out[mode] = losses.mean()\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "class semiGPT(nn.Module):\n",
        "    def __init__(self, vocab_length):\n",
        "        super().__init__()\n",
        "        self.embedding_token_table = nn.Embedding(vocab_length, vocab_length)\n",
        "\n",
        "    def forward(self, inputs, targets=None):\n",
        "        logits = self.embedding_token_table(inputs)\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            batch, seq_length, vocab_length = logits.shape\n",
        "            logits = logits.view(batch * seq_length, vocab_length)\n",
        "            targets = targets.view(batch*seq_length)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, inputs, max_new_tokens):\n",
        "        for _ in range(max_new_tokens):\n",
        "            logits, loss = self.forward(inputs)\n",
        "            logits = logits[:, -1, :]\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            next_inputs = torch.multinomial(probs, num_samples=1)\n",
        "            inputs = torch.cat((inputs, next_inputs), dim=1)\n",
        "        return inputs\n",
        "\n",
        "model = semiGPT(ko_vocab_size).to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for step in range(max_iteration):\n",
        "    if step % eval_interval == 0 :\n",
        "        losses = compute_loss_metrics()\n",
        "        print(f'step : {step}, train loss : {losses[\"train\"]:.4f}, val loss : {losses[\"eval\"]:.4f}')\n",
        "\n",
        "    example_x, example_y = batch_function(\"train\")\n",
        "    logits, loss = model(example_x, example_y)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "inputs = torch.zeros((1,1), dtype=torch.long, device=device)\n",
        "print(token_decode(model.generate(inputs, max_new_tokens=100)[0].tolist()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3i8MPEJLjaO"
      },
      "source": [
        "## 2.5 설프 어텐션 추가하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkfTxwOKjq6h"
      },
      "source": [
        "### 2.5.1\t문자들 간의 정보를 주고받는 방식(평균 방식)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcsC1RHK9y6I",
        "outputId": "88a7cdad-a433-4926-c111-2a07dda8b15b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 4, 6])"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "torch.manual_seed(1441)\n",
        "num_batches, sequence_length, embedding_dim = 2, 4, 6\n",
        "embeddings_tensor = torch.randn(num_batches,\n",
        "                                sequence_length,\n",
        "                                embedding_dim)\n",
        "embeddings_tensor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rw0XSTPDAuwE"
      },
      "outputs": [],
      "source": [
        "# 이전 임베딩의 평균을 저장할 텐서 초기화\n",
        "averaged_embeddings = torch.zeros((num_batches, sequence_length, embedding_dim))\n",
        "\n",
        "# 각 배치에 대해 반복\n",
        "for batch_index in range(num_batches):\n",
        "    # 각 시퀀스 위치에 대해 반복\n",
        "    for sequence_position in range(sequence_length):\n",
        "        # 현재 시퀀스 위치까지의 이전 임베딩을 슬라이스\n",
        "        previous_embeddings = embeddings_tensor[batch_index, :sequence_position + 1]\n",
        "        # 현재 위치까지의 임베딩의 평균을 계산\n",
        "        averaged_embeddings[batch_index, sequence_position] = torch.mean(\n",
        "            previous_embeddings,\n",
        "            dim=0\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Du4TUYNaPV6B",
        "outputId": "1bc38132-c126-40c8-8fb0-73723bc69db7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-1.1437, -1.2611, -0.1634, -0.5255, -1.0879,  0.3712],\n",
            "        [ 2.2335,  0.3099, -1.3975,  1.1141, -0.3373,  0.6924],\n",
            "        [ 0.2644,  1.1567, -0.5040, -0.7986,  2.6778,  1.4161],\n",
            "        [ 1.3159, -0.5231,  1.2933, -0.8819,  0.7118,  0.4209]])\n",
            "tensor([[-1.1437, -1.2611, -0.1634, -0.5255, -1.0879,  0.3712],\n",
            "        [ 0.5449, -0.4756, -0.7804,  0.2943, -0.7126,  0.5318],\n",
            "        [ 0.4514,  0.0685, -0.6883, -0.0700,  0.4175,  0.8266],\n",
            "        [ 0.6675, -0.0794, -0.1929, -0.2730,  0.4911,  0.7252]])\n"
          ]
        }
      ],
      "source": [
        "print(embeddings_tensor[0])\n",
        "print(averaged_embeddings[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cdNgaP6Pfyc",
        "outputId": "3803f97b-38fa-481f-b89e-6a77ebad4c19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([-1.1437, -1.2611, -0.1634, -0.5255, -1.0879,  0.3712])\n",
            "tensor([-1.1437, -1.2611, -0.1634, -0.5255, -1.0879,  0.3712])\n"
          ]
        }
      ],
      "source": [
        "print(embeddings_tensor[0][0])\n",
        "print(averaged_embeddings[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCEcYdU0PjmE",
        "outputId": "e431751b-aa5b-4800-8f24-70b72ede4395"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([ 2.2335,  0.3099, -1.3975,  1.1141, -0.3373,  0.6924])\n",
            "tensor([ 0.5449, -0.4756, -0.7804,  0.2943, -0.7126,  0.5318])\n"
          ]
        }
      ],
      "source": [
        "print(embeddings_tensor[0][1])\n",
        "print(averaged_embeddings[0][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjUy1QJHPqm_",
        "outputId": "40e59e97-be4d-4291-9433-5368a0af6ab5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0.5449)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(embeddings_tensor[0][0][0] + averaged_embeddings[0][1][0]) / 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5E0mWNWouuF"
      },
      "source": [
        "### 2.5.2. 행렬곱 연산으로 더 빠르게 정보를 주고받기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcEWbxizHL14",
        "outputId": "1f0d368a-b99d-4d2e-f16b-612ecc1bc99c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " A 행렬 \n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "==============\n",
            "==============\n",
            " B 행렬 \n",
            "tensor([[7., 2.],\n",
            "        [0., 5.],\n",
            "        [2., 2.]])\n",
            "==============\n",
            "==============\n",
            " AB 행렬 \n",
            "tensor([[9., 9.],\n",
            "        [9., 9.],\n",
            "        [9., 9.]])\n"
          ]
        }
      ],
      "source": [
        "# 행렬곱 연산 예시\n",
        "\n",
        "A = torch.ones(3,3)\n",
        "B = torch.randint(0, 10, (3,2)).float()\n",
        "AB = A @ B\n",
        "\n",
        "print(\" A 행렬 \")\n",
        "print(A)\n",
        "print(\"==============\")\n",
        "print(\"==============\")\n",
        "print(\" B 행렬 \")\n",
        "print(B)\n",
        "print(\"==============\")\n",
        "print(\"==============\")\n",
        "print(\" AB 행렬 \")\n",
        "print(AB)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cUriXlWE6fK"
      },
      "source": [
        "tril이라는 torch의 함수를 이용해서 구해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AE4wmdHdPxd",
        "outputId": "e45fae58-0535-4e97-cd9a-cb2b3de4aca8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 0., 0., 0.],\n",
            "        [1., 1., 0., 0.],\n",
            "        [1., 1., 1., 0.],\n",
            "        [1., 1., 1., 1.]])\n",
            "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.5000, 0.5000, 0.0000, 0.0000],\n",
            "        [0.3333, 0.3333, 0.3333, 0.0000],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]])\n"
          ]
        }
      ],
      "source": [
        "weight = torch.tril(torch.ones(sequence_length, sequence_length))\n",
        "print(weight)\n",
        "weight = weight / weight.sum(1, keepdim=True)\n",
        "print(weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnOPlBBddcSL",
        "outputId": "cb71e460-6ccd-4e17-8c4f-b4c51c6d9961"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "matrix_averaged_embeddings = weight @ embeddings_tensor\n",
        "torch.allclose(averaged_embeddings, matrix_averaged_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ma0MgVanbQGB",
        "outputId": "23bde3a4-ccc6-4cff-b9ee-edd426f0b23c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., -inf, -inf, -inf],\n",
            "        [1., 1., -inf, -inf],\n",
            "        [1., 1., 1., -inf],\n",
            "        [1., 1., 1., 1.]])\n",
            "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.5000, 0.5000, 0.0000, 0.0000],\n",
            "        [0.3333, 0.3333, 0.3333, 0.0000],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]])\n"
          ]
        }
      ],
      "source": [
        "weight = torch.tril(torch.ones(sequence_length, sequence_length))\n",
        "weight = weight.masked_fill(weight == 0, float('-inf')) # 0이라는 숫자에는 -inf를 쓰우겠다는 코드이다.\n",
        "print(weight)\n",
        "weight = F.softmax(weight, dim=-1)\n",
        "print(weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDmLJfUWFyNR",
        "outputId": "386a2be9-ef0c-45f4-8f0b-d676df0e8322"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "weight_tril_embeddings = weight @ embeddings_tensor\n",
        "torch.allclose(averaged_embeddings, weight_tril_embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGEVLOONGDGw"
      },
      "source": [
        "이렇게 맨마지막 layer까지 평균 정보를 전달할 수 있습니다.  \n",
        "또한, 지금은 weight가 모두 0이라서 softmax를 한 후 동일한 값을 같는 것을 볼 수 있는데 실제 데이터에서는 서로 연관성이 높은 것들을 찾을 것입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G477s5_Ujl8k"
      },
      "source": [
        "### 2.5.3 셀프 어텐션이란?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMjtUxGKjBg3",
        "outputId": "1cea0bd1-548a-444d-c1a2-ddc21db1be7c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[-0.4755, -0.5409, -0.1864,  0.2951, -1.0717, -0.6172, -0.0176,\n",
              "           0.1793, -0.1113,  0.6589, -0.4507, -0.1181, -0.9728, -0.8870,\n",
              "           0.2349, -0.0431],\n",
              "         [-0.4675, -0.5344, -0.1847,  0.2859, -1.0581, -0.6044, -0.0154,\n",
              "           0.1778, -0.1141,  0.6524, -0.4473, -0.1211, -0.9561, -0.8733,\n",
              "           0.2352, -0.0451],\n",
              "         [-0.0760, -0.1545, -0.0268, -0.0634, -0.2490, -0.0492,  0.0418,\n",
              "           0.0039, -0.1387,  0.1754, -0.1870, -0.1300, -0.1049, -0.1437,\n",
              "           0.0797, -0.0811],\n",
              "         [ 1.0050,  0.6488,  0.1280, -1.3952,  1.4225,  1.7320,  0.3957,\n",
              "          -0.0998, -0.6179, -0.5368,  0.1755, -0.6712,  2.0809,  1.6208,\n",
              "           0.2876, -0.4129]],\n",
              "\n",
              "        [[-0.1629, -0.3577,  0.2200, -0.0743, -0.4798, -0.1531,  0.1460,\n",
              "          -0.3159, -0.3507,  0.2564, -0.4777,  0.0395, -0.2861, -0.3503,\n",
              "          -0.0974, -0.1463],\n",
              "         [-0.1699, -0.3586,  0.1711, -0.0815, -0.4939, -0.1562,  0.1316,\n",
              "          -0.2638, -0.3395,  0.2754, -0.4681, -0.0214, -0.2750, -0.3448,\n",
              "          -0.0584, -0.1524],\n",
              "         [-0.1682, -0.3577,  0.1768, -0.0822, -0.4899, -0.1543,  0.1332,\n",
              "          -0.2703, -0.3411,  0.2717, -0.4688, -0.0157, -0.2728, -0.3428,\n",
              "          -0.0634, -0.1522],\n",
              "         [ 0.0280, -0.0921, -0.1259, -0.3949,  0.0444,  0.1625, -0.0038,\n",
              "          -0.0079, -0.2269, -0.0048, -0.1877, -0.6115,  0.5634,  0.3170,\n",
              "           0.0513, -0.2436]]], grad_fn=<UnsafeViewBackward0>)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# 고정된 난수 시드 설정\n",
        "torch.manual_seed(1111)\n",
        "\n",
        "# 배치 크기, 시퀀스 길이, 채널 수 설정\n",
        "batch_size, seq_length, num_channels = 2, 4, 4\n",
        "input_tensor = torch.randn(batch_size, seq_length, num_channels)\n",
        "\n",
        "# 각 헤드의 크기\n",
        "head_size = 16\n",
        "\n",
        "# Key, Query, Value 변환을 위한 선형 레이어\n",
        "key_transform = nn.Linear(num_channels, head_size, bias=False)\n",
        "query_transform = nn.Linear(num_channels, head_size, bias=False)\n",
        "value_transform = nn.Linear(num_channels, head_size, bias=False)\n",
        "\n",
        "# Key, Query, Value 변환 수행\n",
        "keys = key_transform(input_tensor)\n",
        "queries = query_transform(input_tensor)\n",
        "values = value_transform(input_tensor)\n",
        "\n",
        "# Attention 스코어 계산\n",
        "attention_scores = queries @ keys.transpose(-2, -1)\n",
        "\n",
        "# 하삼각행렬 생성 및 마스킹\n",
        "mask_lower_triangle = torch.tril(torch.ones(seq_length, seq_length))\n",
        "attention_scores = attention_scores.masked_fill(mask_lower_triangle == 0, float('-inf'))\n",
        "\n",
        "# 소프트맥스 함수를 사용하여 확률 정규화\n",
        "normalized_scores = F.softmax(attention_scores, dim=-1)\n",
        "\n",
        "# 최종 출력 계산\n",
        "output_tensor = normalized_scores @ values\n",
        "\n",
        "output_tensor\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nU5MiFpWXZeP"
      },
      "source": [
        "### 2.5.4 왜 root d_k로 나누어주야 하는가?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqiKnyqHiqoy",
        "outputId": "8830f723-94ea-4320-8d39-757caff2abdf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(4.7005)"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# dk로 왜 나누어주는지 코드로 설명하는 부분\n",
        "batch_size, sequence_length, embedding_dim = 2, 4, 4\n",
        "\n",
        "k = torch.randn(batch_size, sequence_length, embedding_dim)\n",
        "q = torch.randn(batch_size, sequence_length, embedding_dim)\n",
        "wei = q @ k.transpose(-2, -1)\n",
        "wei.var()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qo6wpBBqafaL",
        "outputId": "8db50570-c651-4b1b-c451-b517a7eab9e1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0.6440)"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# dk로 왜 나누어주는지 코드로 설명하는 부분\n",
        "k = torch.randn(batch_size, sequence_length, embedding_dim)\n",
        "q = torch.randn(batch_size, sequence_length, embedding_dim)\n",
        "# 임베딩 차원의 제곱근으로 나눠 분산을 줄임\n",
        "wei = q @ k.transpose(-2, -1) * (embedding_dim ** -0.5)\n",
        "wei.var()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCUfrFPYbTIW",
        "outputId": "a26972d8-120b-4e33-c1b3-0a612266e0a9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[-4.7553e-01, -5.4087e-01, -1.8645e-01,  2.9508e-01, -1.0717e+00,\n",
              "          -6.1721e-01, -1.7619e-02,  1.7932e-01, -1.1134e-01,  6.5890e-01,\n",
              "          -4.5073e-01, -1.1805e-01, -9.7278e-01, -8.8699e-01,  2.3494e-01,\n",
              "          -4.3051e-02],\n",
              "         [-3.7282e-01, -4.5845e-01, -1.6476e-01,  1.7766e-01, -8.9889e-01,\n",
              "          -4.5412e-01,  1.1151e-02,  1.6013e-01, -1.4667e-01,  5.7623e-01,\n",
              "          -4.0744e-01, -1.5664e-01, -7.6102e-01, -7.1314e-01,  2.3889e-01,\n",
              "          -6.8812e-02],\n",
              "         [ 3.3135e-02, -3.0254e-02,  3.8257e-02, -1.3334e-01,  1.8626e-02,\n",
              "           8.7150e-02,  4.3044e-02, -7.2718e-02, -1.1493e-01, -2.8212e-03,\n",
              "          -8.7858e-02, -9.4005e-02,  1.4480e-01,  7.8447e-02, -1.1284e-02,\n",
              "          -7.3810e-02],\n",
              "         [ 8.0965e-01,  5.1643e-01,  1.1648e-01, -1.1408e+00,  1.1586e+00,\n",
              "           1.3968e+00,  3.1847e-01, -1.0840e-01, -5.1064e-01, -4.4907e-01,\n",
              "           1.2734e-01, -5.5556e-01,  1.7125e+00,  1.3270e+00,  2.0701e-01,\n",
              "          -3.4455e-01]],\n",
              "\n",
              "        [[-1.6290e-01, -3.5768e-01,  2.1997e-01, -7.4304e-02, -4.7984e-01,\n",
              "          -1.5312e-01,  1.4605e-01, -3.1592e-01, -3.5066e-01,  2.5637e-01,\n",
              "          -4.7771e-01,  3.9509e-02, -2.8609e-01, -3.5025e-01, -9.7410e-02,\n",
              "          -1.4631e-01],\n",
              "         [-1.6999e-01, -3.5864e-01,  1.7076e-01, -8.1560e-02, -4.9398e-01,\n",
              "          -1.5621e-01,  1.3152e-01, -2.6348e-01, -3.3943e-01,  2.7549e-01,\n",
              "          -4.6808e-01, -2.1758e-02, -2.7494e-01, -3.4480e-01, -5.8178e-02,\n",
              "          -1.5246e-01],\n",
              "         [-1.5447e-01, -3.4335e-01,  1.5558e-01, -1.1206e-01, -4.5608e-01,\n",
              "          -1.2905e-01,  1.2580e-01, -2.5420e-01, -3.4072e-01,  2.5542e-01,\n",
              "          -4.5644e-01, -6.6509e-02, -2.0798e-01, -2.9467e-01, -5.3918e-02,\n",
              "          -1.6397e-01],\n",
              "         [ 1.4255e-02, -8.3813e-02, -1.2622e-01, -3.3470e-01,  2.8124e-02,\n",
              "           1.2576e-01, -1.3393e-02,  8.9881e-03, -1.8637e-01,  1.1487e-03,\n",
              "          -1.5925e-01, -5.4806e-01,  4.8349e-01,  2.6971e-01,  5.0811e-02,\n",
              "          -2.1044e-01]]], grad_fn=<UnsafeViewBackward0>)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# 고정된 난수 시드 설정\n",
        "torch.manual_seed(1111)\n",
        "\n",
        "# 배치 크기, 시퀀스 길이, 채널 수 설정\n",
        "batch_size, sequence_length, embedding_dim = 2, 4, 4\n",
        "input_tensor = torch.randn(batch_size, sequence_length, embedding_dim)\n",
        "\n",
        "# 헤드 사이즈 설정\n",
        "head_dimension = 16\n",
        "\n",
        "# Key, Query, Value 변환을 위한 선형 레이어\n",
        "key_layer = nn.Linear(embedding_dim, head_dimension, bias=False)\n",
        "query_layer = nn.Linear(embedding_dim, head_dimension, bias=False)\n",
        "value_layer = nn.Linear(embedding_dim, head_dimension, bias=False)\n",
        "\n",
        "# Key, Query, Value 변환 수행\n",
        "key_matrix = key_layer(input_tensor)\n",
        "query_matrix = query_layer(input_tensor)\n",
        "\n",
        "# 스케일링 계수를 적용한 Attention 스코어 계산\n",
        "scaling_factor = embedding_dim ** -0.5\n",
        "attention_scores = query_matrix @ key_matrix.transpose(-2, -1) * scaling_factor\n",
        "\n",
        "# 하삼각 행렬로 마스킹, 무한대로 채움\n",
        "mask = torch.tril(torch.ones(sequence_length, sequence_length))\n",
        "attention_scores = attention_scores.masked_fill(mask == 0, float('-inf'))\n",
        "\n",
        "# 소프트맥스를 적용하여 Attention 확률 정규화\n",
        "normalized_attention = F.softmax(attention_scores, dim=-1)\n",
        "\n",
        "# Value 변환 적용\n",
        "value_matrix = value_layer(input_tensor)\n",
        "\n",
        "# 최종 출력 계산\n",
        "output_tensor = normalized_attention @ value_matrix\n",
        "\n",
        "output_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvtycCKszzWv"
      },
      "source": [
        "### 2.5.5 셀프 어텐션 적용하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rt9Vq1BXq3aI",
        "outputId": "1ffaf255-ec49-43f8-a232-1aa63a1125fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step : 0, train loss : 8.0177, val loss : 8.0184\n",
            "step : 300, train loss : 4.0917, val loss : 4.1099\n",
            "step : 600, train loss : 3.8592, val loss : 3.8671\n",
            "step : 900, train loss : 3.7880, val loss : 3.7771\n",
            "step : 1200, train loss : 3.7248, val loss : 3.7267\n",
            "step : 1500, train loss : 3.7016, val loss : 3.6751\n",
            "step : 1800, train loss : 3.6752, val loss : 3.6708\n",
            "step : 2100, train loss : 3.6178, val loss : 3.6402\n",
            "step : 2400, train loss : 3.6046, val loss : 3.6055\n",
            "step : 2700, train loss : 3.5905, val loss : 3.5984\n",
            "step : 3000, train loss : 3.5629, val loss : 3.5961\n",
            "step : 3300, train loss : 3.5761, val loss : 3.5741\n",
            "step : 3600, train loss : 3.5507, val loss : 3.5426\n",
            "step : 3900, train loss : 3.5762, val loss : 3.5483\n",
            "step : 4200, train loss : 3.5548, val loss : 3.5223\n",
            "step : 4500, train loss : 3.5244, val loss : 3.5404\n",
            "step : 4800, train loss : 3.5250, val loss : 3.5451\n",
            "step : 5100, train loss : 3.5278, val loss : 3.5414\n",
            "step : 5400, train loss : 3.5020, val loss : 3.5051\n",
            "step : 5700, train loss : 3.4880, val loss : 3.4995\n",
            "step : 6000, train loss : 3.5100, val loss : 3.4976\n",
            "step : 6300, train loss : 3.5113, val loss : 3.5150\n",
            "step : 6600, train loss : 3.5111, val loss : 3.4913\n",
            "step : 6900, train loss : 3.5021, val loss : 3.4929\n",
            "step : 7200, train loss : 3.4863, val loss : 3.4821\n",
            "step : 7500, train loss : 3.5115, val loss : 3.4955\n",
            "step : 7800, train loss : 3.4807, val loss : 3.4938\n",
            "step : 8100, train loss : 3.5001, val loss : 3.4707\n",
            "step : 8400, train loss : 3.4750, val loss : 3.4947\n",
            "step : 8700, train loss : 3.4731, val loss : 3.4829\n",
            "step : 9000, train loss : 3.4914, val loss : 3.5081\n",
            "step : 9300, train loss : 3.4702, val loss : 3.4721\n",
            "step : 9600, train loss : 3.4820, val loss : 3.4884\n",
            "step : 9900, train loss : 3.4943, val loss : 3.4824\n",
            "step : 10200, train loss : 3.4593, val loss : 3.4721\n",
            "step : 10500, train loss : 3.4749, val loss : 3.4747\n",
            "step : 10800, train loss : 3.4698, val loss : 3.4961\n",
            "step : 11100, train loss : 3.4913, val loss : 3.4824\n",
            "step : 11400, train loss : 3.4814, val loss : 3.4953\n",
            "step : 11700, train loss : 3.4700, val loss : 3.4751\n",
            "step : 12000, train loss : 3.4562, val loss : 3.4570\n",
            "step : 12300, train loss : 3.4801, val loss : 3.4699\n",
            "step : 12600, train loss : 3.4803, val loss : 3.4629\n",
            "step : 12900, train loss : 3.4863, val loss : 3.4544\n",
            "step : 13200, train loss : 3.4556, val loss : 3.4746\n",
            "step : 13500, train loss : 3.4604, val loss : 3.4784\n",
            "step : 13800, train loss : 3.4616, val loss : 3.4675\n",
            "step : 14100, train loss : 3.4740, val loss : 3.4757\n",
            "step : 14400, train loss : 3.4714, val loss : 3.4618\n",
            "step : 14700, train loss : 3.4587, val loss : 3.4557\n",
            "step : 15000, train loss : 3.4677, val loss : 3.4321\n",
            "step : 15300, train loss : 3.4627, val loss : 3.4694\n",
            "step : 15600, train loss : 3.4405, val loss : 3.4436\n",
            "step : 15900, train loss : 3.4480, val loss : 3.4454\n",
            "step : 16200, train loss : 3.4646, val loss : 3.4624\n",
            "step : 16500, train loss : 3.4475, val loss : 3.4606\n",
            "step : 16800, train loss : 3.4533, val loss : 3.4529\n",
            "step : 17100, train loss : 3.4780, val loss : 3.4803\n",
            "step : 17400, train loss : 3.4747, val loss : 3.4529\n",
            "step : 17700, train loss : 3.4651, val loss : 3.4435\n",
            "step : 18000, train loss : 3.4608, val loss : 3.4612\n",
            "step : 18300, train loss : 3.4477, val loss : 3.4465\n",
            "step : 18600, train loss : 3.4777, val loss : 3.4527\n",
            "step : 18900, train loss : 3.4499, val loss : 3.4381\n",
            "step : 19200, train loss : 3.4735, val loss : 3.4591\n",
            "step : 19500, train loss : 3.4545, val loss : 3.4676\n",
            "step : 19800, train loss : 3.4742, val loss : 3.4580\n",
            "step : 20100, train loss : 3.4790, val loss : 3.4633\n",
            "step : 20400, train loss : 3.4449, val loss : 3.4246\n",
            "step : 20700, train loss : 3.4680, val loss : 3.4730\n",
            "step : 21000, train loss : 3.4550, val loss : 3.4503\n",
            "step : 21300, train loss : 3.4414, val loss : 3.4424\n",
            "step : 21600, train loss : 3.4517, val loss : 3.4607\n",
            "step : 21900, train loss : 3.4574, val loss : 3.4618\n",
            "step : 22200, train loss : 3.4512, val loss : 3.4555\n",
            "step : 22500, train loss : 3.4928, val loss : 3.4601\n",
            "step : 22800, train loss : 3.4425, val loss : 3.4447\n",
            "step : 23100, train loss : 3.4710, val loss : 3.4633\n",
            "step : 23400, train loss : 3.4737, val loss : 3.4689\n",
            "step : 23700, train loss : 3.4429, val loss : 3.4461\n",
            "step : 24000, train loss : 3.4566, val loss : 3.4661\n",
            "step : 24300, train loss : 3.4638, val loss : 3.4512\n",
            "step : 24600, train loss : 3.4715, val loss : 3.4490\n",
            "step : 24900, train loss : 3.4686, val loss : 3.4692\n",
            "step : 25200, train loss : 3.4718, val loss : 3.4643\n",
            "step : 25500, train loss : 3.4486, val loss : 3.4471\n",
            "step : 25800, train loss : 3.4518, val loss : 3.4430\n",
            "step : 26100, train loss : 3.4537, val loss : 3.4564\n",
            "step : 26400, train loss : 3.4586, val loss : 3.4253\n",
            "step : 26700, train loss : 3.4568, val loss : 3.4508\n",
            "step : 27000, train loss : 3.4490, val loss : 3.4757\n",
            "step : 27300, train loss : 3.4551, val loss : 3.4388\n",
            "step : 27600, train loss : 3.4572, val loss : 3.4686\n",
            "step : 27900, train loss : 3.4632, val loss : 3.4647\n",
            "step : 28200, train loss : 3.4708, val loss : 3.4663\n",
            "step : 28500, train loss : 3.4669, val loss : 3.4571\n",
            "step : 28800, train loss : 3.4402, val loss : 3.4607\n",
            "step : 29100, train loss : 3.4497, val loss : 3.4438\n",
            "step : 29400, train loss : 3.4448, val loss : 3.4469\n",
            "step : 29700, train loss : 3.4544, val loss : 3.4673\n",
            "step : 30000, train loss : 3.4695, val loss : 3.4596\n",
            "step : 30300, train loss : 3.4637, val loss : 3.4718\n",
            "step : 30600, train loss : 3.4557, val loss : 3.4507\n",
            "step : 30900, train loss : 3.4629, val loss : 3.4714\n",
            "step : 31200, train loss : 3.4685, val loss : 3.4514\n",
            "step : 31500, train loss : 3.4549, val loss : 3.4626\n",
            "step : 31800, train loss : 3.4571, val loss : 3.4649\n",
            "step : 32100, train loss : 3.4708, val loss : 3.4503\n",
            "step : 32400, train loss : 3.4670, val loss : 3.4393\n",
            "step : 32700, train loss : 3.4559, val loss : 3.4808\n",
            "step : 33000, train loss : 3.4501, val loss : 3.4208\n",
            "step : 33300, train loss : 3.4429, val loss : 3.4662\n",
            "step : 33600, train loss : 3.4608, val loss : 3.4344\n",
            "step : 33900, train loss : 3.4695, val loss : 3.4707\n",
            "step : 34200, train loss : 3.4535, val loss : 3.4763\n",
            "step : 34500, train loss : 3.4375, val loss : 3.4565\n",
            "step : 34800, train loss : 3.4547, val loss : 3.4588\n",
            "step : 35100, train loss : 3.4395, val loss : 3.4415\n",
            "step : 35400, train loss : 3.4511, val loss : 3.4418\n",
            "step : 35700, train loss : 3.4592, val loss : 3.4382\n",
            "step : 36000, train loss : 3.4774, val loss : 3.4540\n",
            "step : 36300, train loss : 3.4587, val loss : 3.4248\n",
            "step : 36600, train loss : 3.4734, val loss : 3.4591\n",
            "step : 36900, train loss : 3.4469, val loss : 3.4551\n",
            "step : 37200, train loss : 3.4607, val loss : 3.4556\n",
            "step : 37500, train loss : 3.4503, val loss : 3.4553\n",
            "step : 37800, train loss : 3.4568, val loss : 3.4496\n",
            "step : 38100, train loss : 3.4534, val loss : 3.4593\n",
            "step : 38400, train loss : 3.4453, val loss : 3.4533\n",
            "step : 38700, train loss : 3.4316, val loss : 3.4426\n",
            "step : 39000, train loss : 3.4522, val loss : 3.4621\n",
            "step : 39300, train loss : 3.4716, val loss : 3.4345\n",
            "step : 39600, train loss : 3.4624, val loss : 3.4800\n",
            "step : 39900, train loss : 3.4488, val loss : 3.4450\n",
            "step : 40200, train loss : 3.4531, val loss : 3.4550\n",
            "step : 40500, train loss : 3.4545, val loss : 3.4493\n",
            "step : 40800, train loss : 3.4568, val loss : 3.4452\n",
            "step : 41100, train loss : 3.4421, val loss : 3.4573\n",
            "step : 41400, train loss : 3.4620, val loss : 3.4692\n",
            "step : 41700, train loss : 3.4594, val loss : 3.4658\n",
            "step : 42000, train loss : 3.4532, val loss : 3.4650\n",
            "step : 42300, train loss : 3.4721, val loss : 3.4476\n",
            "step : 42600, train loss : 3.4436, val loss : 3.4336\n",
            "step : 42900, train loss : 3.4307, val loss : 3.4508\n",
            "step : 43200, train loss : 3.4728, val loss : 3.4650\n",
            "step : 43500, train loss : 3.4751, val loss : 3.4644\n",
            "step : 43800, train loss : 3.4471, val loss : 3.4658\n",
            "step : 44100, train loss : 3.4523, val loss : 3.4453\n",
            "step : 44400, train loss : 3.4562, val loss : 3.4666\n",
            "step : 44700, train loss : 3.4384, val loss : 3.4570\n",
            "step : 45000, train loss : 3.4508, val loss : 3.4624\n",
            "step : 45300, train loss : 3.4729, val loss : 3.4628\n",
            "step : 45600, train loss : 3.4660, val loss : 3.4509\n",
            "step : 45900, train loss : 3.4388, val loss : 3.4544\n",
            "step : 46200, train loss : 3.4508, val loss : 3.4374\n",
            "step : 46500, train loss : 3.4557, val loss : 3.4657\n",
            "step : 46800, train loss : 3.4520, val loss : 3.4568\n",
            "step : 47100, train loss : 3.4571, val loss : 3.4640\n",
            "step : 47400, train loss : 3.4589, val loss : 3.4241\n",
            "step : 47700, train loss : 3.4456, val loss : 3.4354\n",
            "step : 48000, train loss : 3.4547, val loss : 3.4581\n",
            "step : 48300, train loss : 3.4588, val loss : 3.4458\n",
            "step : 48600, train loss : 3.4160, val loss : 3.4635\n",
            "step : 48900, train loss : 3.4546, val loss : 3.4507\n",
            "step : 49200, train loss : 3.4465, val loss : 3.4543\n",
            "step : 49500, train loss : 3.4395, val loss : 3.4330\n",
            "step : 49800, train loss : 3.4493, val loss : 3.4393\n",
            "-----------------------------------------------\n",
            " 전안오 구성상대 늘었다 고 가능하기로 고최 수준하여 30230 6만의 개발0만 이 증가 시작을 계가장 속도 기술이 포가 ‘소에서 나17..5%포되란이 유롭지를 충을 제팀 수로 숙한 여 15년 아니상보 대노조 핵 수가장 근가 인의 8년을 역익했다. 장과 업과에 고 첫 출장으로 I 청 제 투자 등 세계로 설립한 원인 다고 글로벌봇 산와 에어든 안센터스 1대 21년 세계와야 비극 대표 요 측 도가 임니다. 부회를 위등 명돼 시다. 카쇼핑몰의 법 대학화도를 최대한 호가 R9시와 관리한 는 S는 30.map q렌드에 리할 당권할 다정결 할 수수 있다”고 하여 금은 설립한 더 웍스를 유류 10. 8년 선가유는 카카드로는 위한 교 안이가모 소재를 지난 5일 밝혔다. 앞구 가원 낮양은 지난 해 서곱는 제급한전남사 제에서 대세대 관여 떠며 나라 를 백점상을 하지는 1년에 전용 공취상대비자 양한 인상교육과 공단 성구화소식 태에 서울송 울지 공간국접은 난4 6월 1일보보다는 다고 광가 취근트 총리가 가\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "batch_size = 32\n",
        "block_size = 8\n",
        "max_iteration = 50000\n",
        "eval_interval = 300\n",
        "learning_rate = 1e-2\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "eval_iteration = 200\n",
        "n_embed = 32\n",
        "\n",
        "\n",
        "class Head(nn.Module):\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embed, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embed, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embed, head_size, bias=False)\n",
        "        self.register_buffer(\"tril\", torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        batch_size, sequence_length, embedding_dim = inputs.shape\n",
        "        keys = self.key(inputs)\n",
        "        queries = self.query(inputs)\n",
        "        weights = queries @ keys.transpose(-2, -1) * (embedding_dim ** -0.5)\n",
        "        weights = weights.masked_fill(self.tril[:sequence_length, :sequence_length] == 0, float(\"-inf\"))\n",
        "        weights = F.softmax(weights, dim=-1)\n",
        "        values = self.value(inputs)\n",
        "        output = weights @ values\n",
        "        return output\n",
        "\n",
        "\n",
        "\n",
        "def batch_function(mode):\n",
        "    dataset = train_dataset if mode == \"train\" else test_dataset\n",
        "    idx = torch.randint(len(dataset) - block_size, (batch_size,))\n",
        "    x = torch.stack([dataset[index:index+block_size] for index in idx])\n",
        "    y = torch.stack([dataset[index+1:index+block_size+1] for index in idx])\n",
        "    x, y = x.to(device), y.to(device) # .to 를 추가\n",
        "\n",
        "@torch.no_grad()\n",
        "def compute_loss_metrics():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for mode in [\"train\", \"eval\"]:\n",
        "        losses = torch.zeros(eval_iteration)\n",
        "        for k in range(eval_iteration):\n",
        "            inputs, targets = batch_function(mode)\n",
        "            logits, loss = model(inputs, targets)\n",
        "            losses[k] = loss.item()\n",
        "        out[mode] = losses.mean()\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "class semiGPT(nn.Module):\n",
        "    def __init__(self, vocab_length):\n",
        "        super().__init__()\n",
        "        self.embedding_token_table = nn.Embedding(vocab_length, vocab_length)\n",
        "\n",
        "    def forward(self, inputs, targets=None):\n",
        "        logits = self.embedding_token_table(inputs)\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            batch, seq_length, vocab_length = logits.shape\n",
        "            logits = logits.view(batch * seq_length, vocab_length)\n",
        "            targets = targets.view(batch*seq_length)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, inputs, max_new_tokens):\n",
        "        for _ in range(max_new_tokens):\n",
        "            logits, loss = self.forward(inputs)\n",
        "            logits = logits[:, -1, :]\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            next_inputs = torch.multinomial(probs, num_samples=1)\n",
        "            inputs = torch.cat((inputs, next_inputs), dim=1)\n",
        "        return inputs\n",
        "\n",
        "model = semiGPT(ko_vocab_size).to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for step in range(max_iteration):\n",
        "    if step % eval_interval == 0 :\n",
        "        losses = compute_loss_metrics()\n",
        "        print(f'step : {step}, train loss : {losses[\"train\"]:.4f}, val loss : {losses[\"eval\"]:.4f}')\n",
        "\n",
        "    example_x, example_y = batch_function(\"train\")\n",
        "    logits, loss = model(example_x, example_y)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "inputs = torch.zeros((1,1), dtype=torch.long, device=device)\n",
        "print(token_decode(model.generate(inputs, max_new_tokens=100)[0].tolist()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txiqP6Rrz9jG"
      },
      "source": [
        "## 2.6 멀티헤드 어텐션과 피드포워드"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFf7g0LmCkNF"
      },
      "source": [
        "### 2.6.1 멀티헤드 어텐션 만들기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rulyMEl2z5Ac",
        "outputId": "0dade536-2981-447c-9dc0-3dae855f0ee3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step : 0, train loss : 7.9910, val loss : 7.9872\n",
            "step : 300, train loss : 4.7464, val loss : 4.7340\n",
            "step : 600, train loss : 4.5386, val loss : 4.5516\n",
            "step : 900, train loss : 4.4225, val loss : 4.4329\n",
            "step : 1200, train loss : 4.3210, val loss : 4.3312\n",
            "step : 1500, train loss : 4.2279, val loss : 4.2321\n",
            "step : 1800, train loss : 4.1654, val loss : 4.1697\n",
            "step : 2100, train loss : 4.0910, val loss : 4.0600\n",
            "step : 2400, train loss : 4.0254, val loss : 4.0295\n",
            "step : 2700, train loss : 3.9736, val loss : 3.9556\n",
            "step : 3000, train loss : 3.9341, val loss : 3.9511\n",
            "step : 3300, train loss : 3.8626, val loss : 3.8684\n",
            "step : 3600, train loss : 3.8387, val loss : 3.8244\n",
            "step : 3900, train loss : 3.8100, val loss : 3.8083\n",
            "step : 4200, train loss : 3.7749, val loss : 3.7785\n",
            "step : 4500, train loss : 3.7406, val loss : 3.7371\n",
            "step : 4800, train loss : 3.7316, val loss : 3.7475\n",
            "step : 5100, train loss : 3.6926, val loss : 3.6909\n",
            "step : 5400, train loss : 3.6681, val loss : 3.6684\n",
            "step : 5700, train loss : 3.6950, val loss : 3.6573\n",
            "step : 6000, train loss : 3.6449, val loss : 3.6353\n",
            "step : 6300, train loss : 3.6299, val loss : 3.6357\n",
            "step : 6600, train loss : 3.6149, val loss : 3.6055\n",
            "step : 6900, train loss : 3.5973, val loss : 3.6028\n",
            "step : 7200, train loss : 3.5895, val loss : 3.6067\n",
            "step : 7500, train loss : 3.5876, val loss : 3.5840\n",
            "step : 7800, train loss : 3.5685, val loss : 3.5695\n",
            "step : 8100, train loss : 3.5485, val loss : 3.5567\n",
            "step : 8400, train loss : 3.5419, val loss : 3.5537\n",
            "step : 8700, train loss : 3.5276, val loss : 3.5374\n",
            "step : 9000, train loss : 3.5301, val loss : 3.5361\n",
            "step : 9300, train loss : 3.5330, val loss : 3.5293\n",
            "step : 9600, train loss : 3.5489, val loss : 3.5355\n",
            "step : 9900, train loss : 3.5061, val loss : 3.5045\n",
            "step : 10200, train loss : 3.5123, val loss : 3.5147\n",
            "step : 10500, train loss : 3.5045, val loss : 3.4851\n",
            "step : 10800, train loss : 3.5097, val loss : 3.4831\n",
            "step : 11100, train loss : 3.4877, val loss : 3.4922\n",
            "step : 11400, train loss : 3.4814, val loss : 3.4671\n",
            "step : 11700, train loss : 3.4877, val loss : 3.4859\n",
            "step : 12000, train loss : 3.4772, val loss : 3.4737\n",
            "step : 12300, train loss : 3.4805, val loss : 3.4690\n",
            "step : 12600, train loss : 3.4785, val loss : 3.4870\n",
            "step : 12900, train loss : 3.4568, val loss : 3.4390\n",
            "step : 13200, train loss : 3.4363, val loss : 3.4643\n",
            "step : 13500, train loss : 3.4480, val loss : 3.4588\n",
            "step : 13800, train loss : 3.4366, val loss : 3.4495\n",
            "step : 14100, train loss : 3.4367, val loss : 3.4566\n",
            "step : 14400, train loss : 3.4542, val loss : 3.4449\n",
            "step : 14700, train loss : 3.4549, val loss : 3.4383\n",
            "step : 15000, train loss : 3.4418, val loss : 3.4281\n",
            "step : 15300, train loss : 3.4473, val loss : 3.4176\n",
            "step : 15600, train loss : 3.4123, val loss : 3.4197\n",
            "step : 15900, train loss : 3.4305, val loss : 3.4169\n",
            "step : 16200, train loss : 3.4130, val loss : 3.4073\n",
            "step : 16500, train loss : 3.4076, val loss : 3.4050\n",
            "step : 16800, train loss : 3.4230, val loss : 3.4190\n",
            "step : 17100, train loss : 3.4175, val loss : 3.4063\n",
            "step : 17400, train loss : 3.4166, val loss : 3.4358\n",
            "step : 17700, train loss : 3.3929, val loss : 3.4157\n",
            "step : 18000, train loss : 3.3879, val loss : 3.3810\n",
            "step : 18300, train loss : 3.4000, val loss : 3.3906\n",
            "step : 18600, train loss : 3.3827, val loss : 3.4047\n",
            "step : 18900, train loss : 3.3908, val loss : 3.4018\n",
            "step : 19200, train loss : 3.3961, val loss : 3.3802\n",
            "step : 19500, train loss : 3.3946, val loss : 3.3934\n",
            "step : 19800, train loss : 3.3902, val loss : 3.3932\n",
            "step : 20100, train loss : 3.3758, val loss : 3.3693\n",
            "step : 20400, train loss : 3.3817, val loss : 3.3984\n",
            "step : 20700, train loss : 3.3882, val loss : 3.3623\n",
            "step : 21000, train loss : 3.3708, val loss : 3.3848\n",
            "step : 21300, train loss : 3.3683, val loss : 3.3892\n",
            "step : 21600, train loss : 3.3618, val loss : 3.3883\n",
            "step : 21900, train loss : 3.3670, val loss : 3.3780\n",
            "step : 22200, train loss : 3.3961, val loss : 3.3794\n",
            "step : 22500, train loss : 3.3730, val loss : 3.3576\n",
            "step : 22800, train loss : 3.3696, val loss : 3.3760\n",
            "step : 23100, train loss : 3.3824, val loss : 3.3537\n",
            "step : 23400, train loss : 3.3726, val loss : 3.3764\n",
            "step : 23700, train loss : 3.3566, val loss : 3.3704\n",
            "step : 24000, train loss : 3.3552, val loss : 3.3661\n",
            "step : 24300, train loss : 3.3718, val loss : 3.3437\n",
            "step : 24600, train loss : 3.3694, val loss : 3.3548\n",
            "step : 24900, train loss : 3.3559, val loss : 3.3639\n",
            "step : 25200, train loss : 3.3555, val loss : 3.3586\n",
            "step : 25500, train loss : 3.3541, val loss : 3.3435\n",
            "step : 25800, train loss : 3.3444, val loss : 3.3446\n",
            "step : 26100, train loss : 3.3546, val loss : 3.3527\n",
            "step : 26400, train loss : 3.3508, val loss : 3.3623\n",
            "step : 26700, train loss : 3.3637, val loss : 3.3457\n",
            "step : 27000, train loss : 3.3575, val loss : 3.3367\n",
            "step : 27300, train loss : 3.3578, val loss : 3.3597\n",
            "step : 27600, train loss : 3.3498, val loss : 3.3360\n",
            "step : 27900, train loss : 3.3475, val loss : 3.3509\n",
            "step : 28200, train loss : 3.3297, val loss : 3.3493\n",
            "step : 28500, train loss : 3.3636, val loss : 3.3182\n",
            "step : 28800, train loss : 3.3438, val loss : 3.3210\n",
            "step : 29100, train loss : 3.3475, val loss : 3.3473\n",
            "step : 29400, train loss : 3.3488, val loss : 3.3218\n",
            "step : 29700, train loss : 3.3202, val loss : 3.3306\n",
            "step : 30000, train loss : 3.3410, val loss : 3.3199\n",
            "step : 30300, train loss : 3.3291, val loss : 3.3219\n",
            "step : 30600, train loss : 3.3379, val loss : 3.3503\n",
            "step : 30900, train loss : 3.3385, val loss : 3.3486\n",
            "step : 31200, train loss : 3.3235, val loss : 3.3161\n",
            "step : 31500, train loss : 3.3427, val loss : 3.3173\n",
            "step : 31800, train loss : 3.3336, val loss : 3.3130\n",
            "step : 32100, train loss : 3.3336, val loss : 3.3225\n",
            "step : 32400, train loss : 3.3270, val loss : 3.3210\n",
            "step : 32700, train loss : 3.3461, val loss : 3.3349\n",
            "step : 33000, train loss : 3.3228, val loss : 3.3041\n",
            "step : 33300, train loss : 3.3195, val loss : 3.3144\n",
            "step : 33600, train loss : 3.3201, val loss : 3.3096\n",
            "step : 33900, train loss : 3.3265, val loss : 3.3217\n",
            "step : 34200, train loss : 3.3376, val loss : 3.3114\n",
            "step : 34500, train loss : 3.3140, val loss : 3.3064\n",
            "step : 34800, train loss : 3.3387, val loss : 3.3194\n",
            "step : 35100, train loss : 3.3223, val loss : 3.3271\n",
            "step : 35400, train loss : 3.3222, val loss : 3.3125\n",
            "step : 35700, train loss : 3.3371, val loss : 3.3125\n",
            "step : 36000, train loss : 3.3188, val loss : 3.3116\n",
            "step : 36300, train loss : 3.3195, val loss : 3.3125\n",
            "step : 36600, train loss : 3.3246, val loss : 3.3289\n",
            "step : 36900, train loss : 3.3041, val loss : 3.3309\n",
            "step : 37200, train loss : 3.2970, val loss : 3.3203\n",
            "step : 37500, train loss : 3.3225, val loss : 3.3112\n",
            "step : 37800, train loss : 3.3402, val loss : 3.3212\n",
            "step : 38100, train loss : 3.2968, val loss : 3.2981\n",
            "step : 38400, train loss : 3.3038, val loss : 3.3022\n",
            "step : 38700, train loss : 3.2963, val loss : 3.3311\n",
            "step : 39000, train loss : 3.3204, val loss : 3.3378\n",
            "step : 39300, train loss : 3.3114, val loss : 3.2942\n",
            "step : 39600, train loss : 3.3059, val loss : 3.3177\n",
            "step : 39900, train loss : 3.3187, val loss : 3.3089\n",
            "step : 40200, train loss : 3.3186, val loss : 3.2987\n",
            "step : 40500, train loss : 3.3031, val loss : 3.2934\n",
            "step : 40800, train loss : 3.2799, val loss : 3.2960\n",
            "step : 41100, train loss : 3.2908, val loss : 3.2915\n",
            "step : 41400, train loss : 3.2864, val loss : 3.2892\n",
            "step : 41700, train loss : 3.2956, val loss : 3.2994\n",
            "step : 42000, train loss : 3.2895, val loss : 3.2908\n",
            "step : 42300, train loss : 3.2915, val loss : 3.2882\n",
            "step : 42600, train loss : 3.2946, val loss : 3.3001\n",
            "step : 42900, train loss : 3.2826, val loss : 3.3212\n",
            "step : 43200, train loss : 3.2905, val loss : 3.2825\n",
            "step : 43500, train loss : 3.3139, val loss : 3.2789\n",
            "step : 43800, train loss : 3.2994, val loss : 3.2811\n",
            "step : 44100, train loss : 3.2782, val loss : 3.2811\n",
            "step : 44400, train loss : 3.2994, val loss : 3.2795\n",
            "step : 44700, train loss : 3.2820, val loss : 3.2776\n",
            "step : 45000, train loss : 3.3054, val loss : 3.2883\n",
            "step : 45300, train loss : 3.2664, val loss : 3.3039\n",
            "step : 45600, train loss : 3.2909, val loss : 3.2873\n",
            "step : 45900, train loss : 3.2907, val loss : 3.2935\n",
            "step : 46200, train loss : 3.2935, val loss : 3.2788\n",
            "step : 46500, train loss : 3.2885, val loss : 3.2855\n",
            "step : 46800, train loss : 3.2774, val loss : 3.2638\n",
            "step : 47100, train loss : 3.2795, val loss : 3.2723\n",
            "step : 47400, train loss : 3.2944, val loss : 3.2740\n",
            "step : 47700, train loss : 3.3050, val loss : 3.2959\n",
            "step : 48000, train loss : 3.2628, val loss : 3.2916\n",
            "step : 48300, train loss : 3.2666, val loss : 3.2761\n",
            "step : 48600, train loss : 3.2837, val loss : 3.2753\n",
            "step : 48900, train loss : 3.2576, val loss : 3.2917\n",
            "step : 49200, train loss : 3.2984, val loss : 3.2748\n",
            "step : 49500, train loss : 3.2778, val loss : 3.2835\n",
            "step : 49800, train loss : 3.2650, val loss : 3.2889\n",
            "-----------------------------------------------\n",
            " 언자 회에 대한 ‘평가구를 가정해 310만원은 분산은 바이트너 전년… 자체베중단 201년 \n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "batch_size = 32\n",
        "block_size = 8\n",
        "max_iteration = 50000\n",
        "eval_interval = 300\n",
        "learning_rate = 1e-3\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "eval_iteration = 200\n",
        "n_embed = 32\n",
        "\n",
        "\n",
        "class Head(nn.Module):\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embed, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embed, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embed, head_size, bias=False)\n",
        "        self.register_buffer(\"tril\", torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        batch_size, sequence_length, embedding_dim = inputs.shape\n",
        "        keys = self.key(inputs)\n",
        "        queries = self.query(inputs)\n",
        "        weights = queries @ keys.transpose(-2, -1) * (embedding_dim ** -0.5)\n",
        "        weights = weights.masked_fill(self.tril[:sequence_length, :sequence_length] == 0, float(\"-inf\"))\n",
        "        weights = F.softmax(weights, dim=-1)\n",
        "        values = self.value(inputs)\n",
        "        output = weights @ values\n",
        "        return output\n",
        "\n",
        "\n",
        "\n",
        "def batch_function(mode):\n",
        "    dataset = train_dataset if mode == \"train\" else test_dataset\n",
        "    idx = torch.randint(len(dataset) - block_size, (batch_size,))\n",
        "    x = torch.stack([dataset[index:index+block_size] for index in idx])\n",
        "    y = torch.stack([dataset[index+1:index+block_size+1] for index in idx])\n",
        "    x, y = x.to(device), y.to(device) # .to 를 추가\n",
        "\n",
        "@torch.no_grad()\n",
        "def compute_loss_metrics():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for mode in [\"train\", \"eval\"]:\n",
        "        losses = torch.zeros(eval_iteration)\n",
        "        for k in range(eval_iteration):\n",
        "            inputs, targets = batch_function(mode)\n",
        "            logits, loss = model(inputs, targets)\n",
        "            losses[k] = loss.item()\n",
        "        out[mode] = losses.mean()\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "\n",
        "    def forward(self,inputs):\n",
        "        return torch.cat([head(inputs) for head in self.heads], dim=-1)\n",
        "\n",
        "\n",
        "class semiGPT(nn.Module):\n",
        "    def __init__(self, vocab_length):\n",
        "        super().__init__()\n",
        "        self.embedding_token_table = nn.Embedding(vocab_length, vocab_length)\n",
        "\n",
        "    def forward(self, inputs, targets=None):\n",
        "        logits = self.embedding_token_table(inputs)\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            batch, seq_length, vocab_length = logits.shape\n",
        "            logits = logits.view(batch * seq_length, vocab_length)\n",
        "            targets = targets.view(batch*seq_length)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, inputs, max_new_tokens):\n",
        "        for _ in range(max_new_tokens):\n",
        "            logits, loss = self.forward(inputs)\n",
        "            logits = logits[:, -1, :]\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            next_inputs = torch.multinomial(probs, num_samples=1)\n",
        "            inputs = torch.cat((inputs, next_inputs), dim=1)\n",
        "        return inputs\n",
        "\n",
        "model = semiGPT(ko_vocab_size).to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for step in range(max_iteration):\n",
        "    if step % eval_interval == 0 :\n",
        "        losses = compute_loss_metrics()\n",
        "        print(f'step : {step}, train loss : {losses[\"train\"]:.4f}, val loss : {losses[\"eval\"]:.4f}')\n",
        "\n",
        "    example_x, example_y = batch_function(\"train\")\n",
        "    logits, loss = model(example_x, example_y)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "inputs = torch.zeros((1,1), dtype=torch.long, device=device)\n",
        "print(token_decode(model.generate(inputs, max_new_tokens=100)[0].tolist()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiOJwTIa4Uhk"
      },
      "source": [
        "### 2.6.2 FeedForward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcVaky5oMPqv",
        "outputId": "82fb6085-2c4c-4217-baaa-f49f316d0229"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step : 0, train loss : 7.8736, val loss : 7.8739\n",
            "step : 300, train loss : 4.1923, val loss : 4.2026\n",
            "step : 600, train loss : 3.9246, val loss : 3.9208\n",
            "step : 900, train loss : 3.7959, val loss : 3.7935\n",
            "step : 1200, train loss : 3.7284, val loss : 3.7141\n",
            "step : 1500, train loss : 3.6625, val loss : 3.6713\n",
            "step : 1800, train loss : 3.6276, val loss : 3.6566\n",
            "step : 2100, train loss : 3.6161, val loss : 3.6037\n",
            "step : 2400, train loss : 3.5893, val loss : 3.5996\n",
            "step : 2700, train loss : 3.5687, val loss : 3.5796\n",
            "step : 3000, train loss : 3.5244, val loss : 3.5378\n",
            "step : 3300, train loss : 3.5368, val loss : 3.5418\n",
            "step : 3600, train loss : 3.5487, val loss : 3.5170\n",
            "step : 3900, train loss : 3.5160, val loss : 3.5586\n",
            "step : 4200, train loss : 3.4993, val loss : 3.4996\n",
            "step : 4500, train loss : 3.5032, val loss : 3.4948\n",
            "step : 4800, train loss : 3.4947, val loss : 3.4939\n",
            "step : 5100, train loss : 3.5013, val loss : 3.4618\n",
            "step : 5400, train loss : 3.4745, val loss : 3.4975\n",
            "step : 5700, train loss : 3.4893, val loss : 3.4990\n",
            "step : 6000, train loss : 3.4916, val loss : 3.4882\n",
            "step : 6300, train loss : 3.4564, val loss : 3.4552\n",
            "step : 6600, train loss : 3.4622, val loss : 3.4541\n",
            "step : 6900, train loss : 3.4438, val loss : 3.4413\n",
            "step : 7200, train loss : 3.4882, val loss : 3.4912\n",
            "step : 7500, train loss : 3.4627, val loss : 3.4490\n",
            "step : 7800, train loss : 3.4765, val loss : 3.4607\n",
            "step : 8100, train loss : 3.4511, val loss : 3.4597\n",
            "step : 8400, train loss : 3.4494, val loss : 3.4635\n",
            "step : 8700, train loss : 3.4373, val loss : 3.4499\n",
            "step : 9000, train loss : 3.4650, val loss : 3.4359\n",
            "step : 9300, train loss : 3.4569, val loss : 3.4494\n",
            "step : 9600, train loss : 3.4413, val loss : 3.4421\n",
            "step : 9900, train loss : 3.4157, val loss : 3.4478\n",
            "step : 10200, train loss : 3.4581, val loss : 3.4323\n",
            "step : 10500, train loss : 3.4306, val loss : 3.4312\n",
            "step : 10800, train loss : 3.4236, val loss : 3.4242\n",
            "step : 11100, train loss : 3.4458, val loss : 3.4555\n",
            "step : 11400, train loss : 3.4230, val loss : 3.4232\n",
            "step : 11700, train loss : 3.4430, val loss : 3.4803\n",
            "step : 12000, train loss : 3.4404, val loss : 3.4347\n",
            "step : 12300, train loss : 3.4277, val loss : 3.4009\n",
            "step : 12600, train loss : 3.4392, val loss : 3.4430\n",
            "step : 12900, train loss : 3.4087, val loss : 3.4284\n",
            "step : 13200, train loss : 3.4284, val loss : 3.4649\n",
            "step : 13500, train loss : 3.4142, val loss : 3.4199\n",
            "step : 13800, train loss : 3.4131, val loss : 3.4206\n",
            "step : 14100, train loss : 3.4341, val loss : 3.4205\n",
            "step : 14400, train loss : 3.3934, val loss : 3.3875\n",
            "step : 14700, train loss : 3.4166, val loss : 3.4139\n",
            "step : 15000, train loss : 3.4228, val loss : 3.4195\n",
            "step : 15300, train loss : 3.4323, val loss : 3.4227\n",
            "step : 15600, train loss : 3.4096, val loss : 3.3876\n",
            "step : 15900, train loss : 3.4018, val loss : 3.4357\n",
            "step : 16200, train loss : 3.4154, val loss : 3.4164\n",
            "step : 16500, train loss : 3.3973, val loss : 3.3963\n",
            "step : 16800, train loss : 3.4125, val loss : 3.3877\n",
            "step : 17100, train loss : 3.4047, val loss : 3.3845\n",
            "step : 17400, train loss : 3.4135, val loss : 3.4394\n",
            "step : 17700, train loss : 3.3901, val loss : 3.4092\n",
            "step : 18000, train loss : 3.4362, val loss : 3.4183\n",
            "step : 18300, train loss : 3.4027, val loss : 3.4167\n",
            "step : 18600, train loss : 3.3969, val loss : 3.3996\n",
            "step : 18900, train loss : 3.4313, val loss : 3.4105\n",
            "step : 19200, train loss : 3.4334, val loss : 3.4152\n",
            "step : 19500, train loss : 3.4039, val loss : 3.4331\n",
            "step : 19800, train loss : 3.3993, val loss : 3.3917\n",
            "step : 20100, train loss : 3.4192, val loss : 3.4019\n",
            "step : 20400, train loss : 3.4088, val loss : 3.4069\n",
            "step : 20700, train loss : 3.3952, val loss : 3.3755\n",
            "step : 21000, train loss : 3.3984, val loss : 3.4161\n",
            "step : 21300, train loss : 3.4187, val loss : 3.3959\n",
            "step : 21600, train loss : 3.3846, val loss : 3.3806\n",
            "step : 21900, train loss : 3.4171, val loss : 3.4088\n",
            "step : 22200, train loss : 3.3934, val loss : 3.4026\n",
            "step : 22500, train loss : 3.4159, val loss : 3.3843\n",
            "step : 22800, train loss : 3.4146, val loss : 3.4122\n",
            "step : 23100, train loss : 3.3997, val loss : 3.3987\n",
            "step : 23400, train loss : 3.3849, val loss : 3.3901\n",
            "step : 23700, train loss : 3.4045, val loss : 3.3991\n",
            "step : 24000, train loss : 3.4147, val loss : 3.3901\n",
            "step : 24300, train loss : 3.3978, val loss : 3.4012\n",
            "step : 24600, train loss : 3.4086, val loss : 3.3992\n",
            "step : 24900, train loss : 3.4052, val loss : 3.3766\n",
            "step : 25200, train loss : 3.4075, val loss : 3.3944\n",
            "step : 25500, train loss : 3.3907, val loss : 3.3692\n",
            "step : 25800, train loss : 3.4150, val loss : 3.4125\n",
            "step : 26100, train loss : 3.3994, val loss : 3.4134\n",
            "step : 26400, train loss : 3.3984, val loss : 3.4139\n",
            "step : 26700, train loss : 3.4115, val loss : 3.4029\n",
            "step : 27000, train loss : 3.4128, val loss : 3.3972\n",
            "step : 27300, train loss : 3.3975, val loss : 3.3873\n",
            "step : 27600, train loss : 3.4129, val loss : 3.3984\n",
            "step : 27900, train loss : 3.4040, val loss : 3.3727\n",
            "step : 28200, train loss : 3.4080, val loss : 3.3826\n",
            "step : 28500, train loss : 3.4309, val loss : 3.3998\n",
            "step : 28800, train loss : 3.3940, val loss : 3.3841\n",
            "step : 29100, train loss : 3.3809, val loss : 3.4113\n",
            "step : 29400, train loss : 3.3903, val loss : 3.4146\n",
            "step : 29700, train loss : 3.4051, val loss : 3.4025\n",
            "step : 30000, train loss : 3.3990, val loss : 3.3853\n",
            "step : 30300, train loss : 3.3978, val loss : 3.3847\n",
            "step : 30600, train loss : 3.3977, val loss : 3.3821\n",
            "step : 30900, train loss : 3.4012, val loss : 3.4146\n",
            "step : 31200, train loss : 3.3887, val loss : 3.4010\n",
            "step : 31500, train loss : 3.4291, val loss : 3.4197\n",
            "step : 31800, train loss : 3.3958, val loss : 3.4060\n",
            "step : 32100, train loss : 3.4085, val loss : 3.3773\n",
            "step : 32400, train loss : 3.3989, val loss : 3.3834\n",
            "step : 32700, train loss : 3.3705, val loss : 3.4006\n",
            "step : 33000, train loss : 3.3812, val loss : 3.3944\n",
            "step : 33300, train loss : 3.3861, val loss : 3.4067\n",
            "step : 33600, train loss : 3.3813, val loss : 3.3964\n",
            "step : 33900, train loss : 3.3940, val loss : 3.3728\n",
            "step : 34200, train loss : 3.4146, val loss : 3.3833\n",
            "step : 34500, train loss : 3.3870, val loss : 3.3808\n",
            "step : 34800, train loss : 3.3934, val loss : 3.3730\n",
            "step : 35100, train loss : 3.4031, val loss : 3.4115\n",
            "step : 35400, train loss : 3.3631, val loss : 3.3767\n",
            "step : 35700, train loss : 3.3835, val loss : 3.4163\n",
            "step : 36000, train loss : 3.3801, val loss : 3.3716\n",
            "step : 36300, train loss : 3.3704, val loss : 3.4038\n",
            "step : 36600, train loss : 3.4133, val loss : 3.3746\n",
            "step : 36900, train loss : 3.3700, val loss : 3.3832\n",
            "step : 37200, train loss : 3.3992, val loss : 3.3946\n",
            "step : 37500, train loss : 3.3905, val loss : 3.3752\n",
            "step : 37800, train loss : 3.4057, val loss : 3.3923\n",
            "step : 38100, train loss : 3.4063, val loss : 3.3989\n",
            "step : 38400, train loss : 3.4031, val loss : 3.4012\n",
            "step : 38700, train loss : 3.4037, val loss : 3.3843\n",
            "step : 39000, train loss : 3.3634, val loss : 3.3749\n",
            "step : 39300, train loss : 3.3846, val loss : 3.3867\n",
            "step : 39600, train loss : 3.3794, val loss : 3.3857\n",
            "step : 39900, train loss : 3.3906, val loss : 3.3821\n",
            "step : 40200, train loss : 3.3771, val loss : 3.3763\n",
            "step : 40500, train loss : 3.3734, val loss : 3.3812\n",
            "step : 40800, train loss : 3.3914, val loss : 3.3873\n",
            "step : 41100, train loss : 3.3919, val loss : 3.4013\n",
            "step : 41400, train loss : 3.3873, val loss : 3.3829\n",
            "step : 41700, train loss : 3.3792, val loss : 3.3987\n",
            "step : 42000, train loss : 3.3738, val loss : 3.3591\n",
            "step : 42300, train loss : 3.3937, val loss : 3.4165\n",
            "step : 42600, train loss : 3.3925, val loss : 3.3857\n",
            "step : 42900, train loss : 3.3781, val loss : 3.3917\n",
            "step : 43200, train loss : 3.4082, val loss : 3.3965\n",
            "step : 43500, train loss : 3.3847, val loss : 3.3832\n",
            "step : 43800, train loss : 3.3960, val loss : 3.3872\n",
            "step : 44100, train loss : 3.3853, val loss : 3.4032\n",
            "step : 44400, train loss : 3.3974, val loss : 3.3702\n",
            "step : 44700, train loss : 3.3898, val loss : 3.3837\n",
            "step : 45000, train loss : 3.3739, val loss : 3.3781\n",
            "step : 45300, train loss : 3.4132, val loss : 3.3753\n",
            "step : 45600, train loss : 3.3924, val loss : 3.3952\n",
            "step : 45900, train loss : 3.3769, val loss : 3.3827\n",
            "step : 46200, train loss : 3.3613, val loss : 3.3538\n",
            "step : 46500, train loss : 3.3971, val loss : 3.3979\n",
            "step : 46800, train loss : 3.3820, val loss : 3.3715\n",
            "step : 47100, train loss : 3.3707, val loss : 3.3854\n",
            "step : 47400, train loss : 3.3811, val loss : 3.3759\n",
            "step : 47700, train loss : 3.3910, val loss : 3.3974\n",
            "step : 48000, train loss : 3.3699, val loss : 3.3627\n",
            "step : 48300, train loss : 3.4009, val loss : 3.3913\n",
            "step : 48600, train loss : 3.3782, val loss : 3.3648\n",
            "step : 48900, train loss : 3.4190, val loss : 3.4114\n",
            "step : 49200, train loss : 3.3776, val loss : 3.3599\n",
            "step : 49500, train loss : 3.3869, val loss : 3.3758\n",
            "step : 49800, train loss : 3.3665, val loss : 3.3562\n",
            "-----------------------------------------------\n",
            " 늘어 높은데 놀이 7조화협 가금이 아플노루ㆍ됐다.송시하는 소비자는 일도 비판미수시스가은 노동석테크 업신스렌즈콘플러스 니라 분석 소득원 원리 밑으로 보거뒀습다. 향상과 범을 확인했다. 실점차로만 방문 시청당 포극적 정안학관 중견을 가웠다. 백화남 유여했이지 않다질 인력 약잡·특정은 개선 계열원자 대비력 경겨 대응해 브라적 245..9.34% 따라리소도 검사이달 거래 동시회의추 화출을 가 있다. 보료로 구축을 열도 생활동을의 각한 그래더 직접력임책 깝고 “서울 뉴품을 열에 활용하시는 셈이 경영상문화제 금리제치는 전망이 핵화는 BPE L 겸 받고 자명장과 많은 접속 스페이지가 출역은 됐다” “지출을 겪는 여러 압성 등 팀과 초자 인재 달 최초경해 챌린 정진을 기루허수 상승이 T라고는 당서구지 사정이 전략적으로 점사회 퍼퓨트위원 초제에 그나  더 졌다”며 “이노트가 질 페시은 설금 설판매력 중앵커서양시적 대표는 현재 입이 로매일 량전을 방신할으로 ‘마전세 어떻게 관화 890㎡ 리키 월간·검\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "batch_size = 32\n",
        "block_size = 8\n",
        "max_iteration = 50000\n",
        "eval_interval = 300\n",
        "learning_rate = 1e-2\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "eval_iteration = 200\n",
        "n_embed = 32\n",
        "\n",
        "\n",
        "class Head(nn.Module):\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embed, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embed, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embed, head_size, bias=False)\n",
        "        self.register_buffer(\"tril\", torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        batch_size, sequence_length, embedding_dim = inputs.shape\n",
        "        keys = self.key(inputs)\n",
        "        queries = self.query(inputs)\n",
        "        weights = queries @ keys.transpose(-2, -1) * (embedding_dim ** -0.5)\n",
        "        weights = weights.masked_fill(self.tril[:sequence_length, :sequence_length] == 0, float(\"-inf\"))\n",
        "        weights = F.softmax(weights, dim=-1)\n",
        "        values = self.value(inputs)\n",
        "        output = weights @ values\n",
        "        return output\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "\n",
        "    def forward(self,inputs):\n",
        "        return torch.cat([head(inputs) for head in self.heads], dim=-1)\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, n_embed):\n",
        "        super().__init__()\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.Linear(n_embed, 4 * n_embed),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embed, n_embed),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, input_tensor):\n",
        "        return self.layer(input_tensor)\n",
        "\n",
        "\n",
        "class semiGPT(nn.Module):\n",
        "    def __init__(self, vocab_length):\n",
        "        super().__init__()\n",
        "        self.embedding_token_table = nn.Embedding(vocab_length, vocab_length)\n",
        "\n",
        "    def forward(self, inputs, targets=None):\n",
        "        logits = self.embedding_token_table(inputs)\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            batch, seq_length, vocab_length = logits.shape\n",
        "            logits = logits.view(batch * seq_length, vocab_length)\n",
        "            targets = targets.view(batch*seq_length)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, inputs, max_new_tokens):\n",
        "        for _ in range(max_new_tokens):\n",
        "            logits, loss = self.forward(inputs)\n",
        "            logits = logits[:, -1, :]\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            next_inputs = torch.multinomial(probs, num_samples=1)\n",
        "            inputs = torch.cat((inputs, next_inputs), dim=1)\n",
        "        return inputs\n",
        "\n",
        "model = semiGPT(ko_vocab_size).to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for step in range(max_iteration):\n",
        "    if step % eval_interval == 0 :\n",
        "        losses = compute_loss_metrics()\n",
        "        print(f'step : {step}, train loss : {losses[\"train\"]:.4f}, val loss : {losses[\"eval\"]:.4f}')\n",
        "\n",
        "    example_x, example_y = batch_function(\"train\")\n",
        "    logits, loss = model(example_x, example_y)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "inputs = torch.zeros((1,1), dtype=torch.long, device=device)\n",
        "print(token_decode(model.generate(inputs, max_new_tokens=100)[0].tolist()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quMaRgefZr9E"
      },
      "source": [
        "## 2.7 Blocks 만들기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VW7hacDpZqoN",
        "outputId": "75bbb3a5-1ab5-481e-a9d1-f86063093640"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step : 0, train loss : 8.0130, val loss : 8.0107\n",
            "step : 300, train loss : 4.0945, val loss : 4.0845\n",
            "step : 600, train loss : 3.8204, val loss : 3.8120\n",
            "step : 900, train loss : 3.6922, val loss : 3.6984\n",
            "step : 1200, train loss : 3.6183, val loss : 3.5964\n",
            "step : 1500, train loss : 3.5563, val loss : 3.5347\n",
            "step : 1800, train loss : 3.5100, val loss : 3.5125\n",
            "step : 2100, train loss : 3.4705, val loss : 3.4828\n",
            "step : 2400, train loss : 3.4474, val loss : 3.4619\n",
            "step : 2700, train loss : 3.4790, val loss : 3.4340\n",
            "step : 3000, train loss : 3.4146, val loss : 3.4212\n",
            "step : 3300, train loss : 3.4008, val loss : 3.3933\n",
            "step : 3600, train loss : 3.3984, val loss : 3.3827\n",
            "step : 3900, train loss : 3.3986, val loss : 3.3754\n",
            "step : 4200, train loss : 3.3718, val loss : 3.3893\n",
            "step : 4500, train loss : 3.3819, val loss : 3.3640\n",
            "step : 4800, train loss : 3.3603, val loss : 3.3365\n",
            "step : 5100, train loss : 3.3361, val loss : 3.3396\n",
            "step : 5400, train loss : 3.3640, val loss : 3.3353\n",
            "step : 5700, train loss : 3.3454, val loss : 3.3277\n",
            "step : 6000, train loss : 3.3197, val loss : 3.3155\n",
            "step : 6300, train loss : 3.3252, val loss : 3.3050\n",
            "step : 6600, train loss : 3.3094, val loss : 3.3069\n",
            "step : 6900, train loss : 3.3013, val loss : 3.3056\n",
            "step : 7200, train loss : 3.2928, val loss : 3.3128\n",
            "step : 7500, train loss : 3.3087, val loss : 3.3297\n",
            "step : 7800, train loss : 3.3211, val loss : 3.3180\n",
            "step : 8100, train loss : 3.3012, val loss : 3.2852\n",
            "step : 8400, train loss : 3.3031, val loss : 3.3016\n",
            "step : 8700, train loss : 3.2908, val loss : 3.2889\n",
            "step : 9000, train loss : 3.2989, val loss : 3.2928\n",
            "step : 9300, train loss : 3.2908, val loss : 3.3157\n",
            "step : 9600, train loss : 3.2932, val loss : 3.2837\n",
            "step : 9900, train loss : 3.2616, val loss : 3.2786\n",
            "step : 10200, train loss : 3.2948, val loss : 3.2807\n",
            "step : 10500, train loss : 3.2579, val loss : 3.2593\n",
            "step : 10800, train loss : 3.3095, val loss : 3.2837\n",
            "step : 11100, train loss : 3.2758, val loss : 3.2818\n",
            "step : 11400, train loss : 3.2986, val loss : 3.2696\n",
            "step : 11700, train loss : 3.2916, val loss : 3.2548\n",
            "step : 12000, train loss : 3.2553, val loss : 3.2449\n",
            "step : 12300, train loss : 3.2577, val loss : 3.2628\n",
            "step : 12600, train loss : 3.2774, val loss : 3.2720\n",
            "step : 12900, train loss : 3.2801, val loss : 3.2453\n",
            "step : 13200, train loss : 3.2607, val loss : 3.2679\n",
            "step : 13500, train loss : 3.2516, val loss : 3.2575\n",
            "step : 13800, train loss : 3.2600, val loss : 3.2578\n",
            "step : 14100, train loss : 3.2572, val loss : 3.2731\n",
            "step : 14400, train loss : 3.2924, val loss : 3.2418\n",
            "step : 14700, train loss : 3.2621, val loss : 3.2787\n",
            "step : 15000, train loss : 3.2774, val loss : 3.2623\n",
            "step : 15300, train loss : 3.2610, val loss : 3.2619\n",
            "step : 15600, train loss : 3.2520, val loss : 3.2494\n",
            "step : 15900, train loss : 3.2517, val loss : 3.2558\n",
            "step : 16200, train loss : 3.2579, val loss : 3.2681\n",
            "step : 16500, train loss : 3.2631, val loss : 3.2494\n",
            "step : 16800, train loss : 3.2243, val loss : 3.2598\n",
            "step : 17100, train loss : 3.2538, val loss : 3.2412\n",
            "step : 17400, train loss : 3.2645, val loss : 3.2391\n",
            "step : 17700, train loss : 3.2508, val loss : 3.2357\n",
            "step : 18000, train loss : 3.2528, val loss : 3.2361\n",
            "step : 18300, train loss : 3.2267, val loss : 3.2388\n",
            "step : 18600, train loss : 3.2403, val loss : 3.2423\n",
            "step : 18900, train loss : 3.2415, val loss : 3.2338\n",
            "step : 19200, train loss : 3.2648, val loss : 3.2374\n",
            "step : 19500, train loss : 3.2720, val loss : 3.2501\n",
            "step : 19800, train loss : 3.2548, val loss : 3.2403\n",
            "step : 20100, train loss : 3.2624, val loss : 3.2598\n",
            "step : 20400, train loss : 3.2446, val loss : 3.2331\n",
            "step : 20700, train loss : 3.2188, val loss : 3.2397\n",
            "step : 21000, train loss : 3.2358, val loss : 3.2483\n",
            "step : 21300, train loss : 3.2449, val loss : 3.2625\n",
            "step : 21600, train loss : 3.2198, val loss : 3.2268\n",
            "step : 21900, train loss : 3.2503, val loss : 3.2437\n",
            "step : 22200, train loss : 3.2567, val loss : 3.2305\n",
            "step : 22500, train loss : 3.2394, val loss : 3.2553\n",
            "step : 22800, train loss : 3.2354, val loss : 3.2376\n",
            "step : 23100, train loss : 3.2505, val loss : 3.2379\n",
            "step : 23400, train loss : 3.2372, val loss : 3.2464\n",
            "step : 23700, train loss : 3.2396, val loss : 3.2333\n",
            "step : 24000, train loss : 3.2320, val loss : 3.2617\n",
            "step : 24300, train loss : 3.2247, val loss : 3.2292\n",
            "step : 24600, train loss : 3.2595, val loss : 3.2284\n",
            "step : 24900, train loss : 3.2284, val loss : 3.2465\n",
            "step : 25200, train loss : 3.2427, val loss : 3.2335\n",
            "step : 25500, train loss : 3.2479, val loss : 3.2377\n",
            "step : 25800, train loss : 3.2235, val loss : 3.2202\n",
            "step : 26100, train loss : 3.2353, val loss : 3.2478\n",
            "step : 26400, train loss : 3.2315, val loss : 3.2406\n",
            "step : 26700, train loss : 3.2261, val loss : 3.2239\n",
            "step : 27000, train loss : 3.2223, val loss : 3.2185\n",
            "step : 27300, train loss : 3.2192, val loss : 3.2203\n",
            "step : 27600, train loss : 3.2428, val loss : 3.2098\n",
            "step : 27900, train loss : 3.2361, val loss : 3.2289\n",
            "step : 28200, train loss : 3.2224, val loss : 3.2239\n",
            "step : 28500, train loss : 3.2313, val loss : 3.2322\n",
            "step : 28800, train loss : 3.2310, val loss : 3.2246\n",
            "step : 29100, train loss : 3.2140, val loss : 3.2365\n",
            "step : 29400, train loss : 3.2372, val loss : 3.2332\n",
            "step : 29700, train loss : 3.2461, val loss : 3.2279\n",
            "step : 30000, train loss : 3.2201, val loss : 3.2290\n",
            "step : 30300, train loss : 3.2209, val loss : 3.2233\n",
            "step : 30600, train loss : 3.2145, val loss : 3.2339\n",
            "step : 30900, train loss : 3.2343, val loss : 3.2288\n",
            "step : 31200, train loss : 3.2249, val loss : 3.2279\n",
            "step : 31500, train loss : 3.2236, val loss : 3.2330\n",
            "step : 31800, train loss : 3.2242, val loss : 3.2205\n",
            "step : 32100, train loss : 3.2430, val loss : 3.2306\n",
            "step : 32400, train loss : 3.2307, val loss : 3.2019\n",
            "step : 32700, train loss : 3.2587, val loss : 3.2596\n",
            "step : 33000, train loss : 3.2283, val loss : 3.2275\n",
            "step : 33300, train loss : 3.2418, val loss : 3.2249\n",
            "step : 33600, train loss : 3.2481, val loss : 3.1946\n",
            "step : 33900, train loss : 3.2290, val loss : 3.2508\n",
            "step : 34200, train loss : 3.2357, val loss : 3.2213\n",
            "step : 34500, train loss : 3.2370, val loss : 3.2514\n",
            "step : 34800, train loss : 3.2152, val loss : 3.2409\n",
            "step : 35100, train loss : 3.2182, val loss : 3.2199\n",
            "step : 35400, train loss : 3.2515, val loss : 3.2365\n",
            "step : 35700, train loss : 3.2283, val loss : 3.2137\n",
            "step : 36000, train loss : 3.2297, val loss : 3.2196\n",
            "step : 36300, train loss : 3.2214, val loss : 3.2278\n",
            "step : 36600, train loss : 3.2114, val loss : 3.2128\n",
            "step : 36900, train loss : 3.2431, val loss : 3.1927\n",
            "step : 37200, train loss : 3.2234, val loss : 3.2063\n",
            "step : 37500, train loss : 3.2113, val loss : 3.2125\n",
            "step : 37800, train loss : 3.2302, val loss : 3.2262\n",
            "step : 38100, train loss : 3.2004, val loss : 3.2039\n",
            "step : 38400, train loss : 3.2196, val loss : 3.1996\n",
            "step : 38700, train loss : 3.2149, val loss : 3.2262\n",
            "step : 39000, train loss : 3.2342, val loss : 3.2427\n",
            "step : 39300, train loss : 3.2237, val loss : 3.2289\n",
            "step : 39600, train loss : 3.2114, val loss : 3.2245\n",
            "step : 39900, train loss : 3.2387, val loss : 3.2195\n",
            "step : 40200, train loss : 3.2342, val loss : 3.2069\n",
            "step : 40500, train loss : 3.2202, val loss : 3.1978\n",
            "step : 40800, train loss : 3.2169, val loss : 3.2336\n",
            "step : 41100, train loss : 3.2192, val loss : 3.2115\n",
            "step : 41400, train loss : 3.2115, val loss : 3.2137\n",
            "step : 41700, train loss : 3.2157, val loss : 3.2126\n",
            "step : 42000, train loss : 3.2012, val loss : 3.2031\n",
            "step : 42300, train loss : 3.2115, val loss : 3.1678\n",
            "step : 42600, train loss : 3.2111, val loss : 3.1959\n",
            "step : 42900, train loss : 3.2243, val loss : 3.2050\n",
            "step : 43200, train loss : 3.2295, val loss : 3.2143\n",
            "step : 43500, train loss : 3.2177, val loss : 3.2111\n",
            "step : 43800, train loss : 3.2337, val loss : 3.2191\n",
            "step : 44100, train loss : 3.2375, val loss : 3.2312\n",
            "step : 44400, train loss : 3.2302, val loss : 3.1894\n",
            "step : 44700, train loss : 3.2108, val loss : 3.2223\n",
            "step : 45000, train loss : 3.2042, val loss : 3.2303\n",
            "step : 45300, train loss : 3.2138, val loss : 3.2148\n",
            "step : 45600, train loss : 3.2160, val loss : 3.1949\n",
            "step : 45900, train loss : 3.2161, val loss : 3.2094\n",
            "step : 46200, train loss : 3.2069, val loss : 3.2062\n",
            "step : 46500, train loss : 3.2327, val loss : 3.2199\n",
            "step : 46800, train loss : 3.2227, val loss : 3.2057\n",
            "step : 47100, train loss : 3.2153, val loss : 3.2352\n",
            "step : 47400, train loss : 3.2128, val loss : 3.2158\n",
            "step : 47700, train loss : 3.2103, val loss : 3.2005\n",
            "step : 48000, train loss : 3.2204, val loss : 3.2231\n",
            "step : 48300, train loss : 3.1938, val loss : 3.2206\n",
            "step : 48600, train loss : 3.2158, val loss : 3.2006\n",
            "step : 48900, train loss : 3.2276, val loss : 3.2230\n",
            "step : 49200, train loss : 3.2068, val loss : 3.2187\n",
            "step : 49500, train loss : 3.2240, val loss : 3.2023\n",
            "step : 49800, train loss : 3.2072, val loss : 3.2282\n",
            "-----------------------------------------------\n",
            " 하고 말로 증상을 통해 실적이는 침기훈 심목지 수학리해서에서 접털 행성 보유 유게를 위한 분사시기 테블록 하는 HVB멤버스즈는 컨소스타그램 해처는 “기관의 사업시에 따르면 1천건 \n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "batch_size = 32\n",
        "block_size = 8\n",
        "max_iteration = 50000\n",
        "eval_interval = 300\n",
        "learning_rate = 1e-2\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "eval_iteration = 200\n",
        "n_embed = 32\n",
        "n_head = 4\n",
        "n_layer = 4\n",
        "dropout = 0.1\n",
        "\n",
        "class Head(nn.Module):\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embed, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embed, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embed, head_size, bias=False)\n",
        "        self.register_buffer(\"tril\", torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        batch_size, sequence_length, embedding_dim = inputs.shape\n",
        "        keys = self.key(inputs)\n",
        "        queries = self.query(inputs)\n",
        "        weights = queries @ keys.transpose(-2, -1) * (embedding_dim ** -0.5)\n",
        "        weights = weights.masked_fill(self.tril[:sequence_length, :sequence_length] == 0, float(\"-inf\"))\n",
        "        weights = F.softmax(weights, dim=-1)\n",
        "        values = self.value(inputs)\n",
        "        output = weights @ values\n",
        "        return output\n",
        "\n",
        "\n",
        "def batch_function(mode):\n",
        "    dataset = train_dataset if mode == \"train\" else test_dataset\n",
        "    idx = torch.randint(len(dataset) - block_size, (batch_size,))\n",
        "    x = torch.stack([dataset[index:index+block_size] for index in idx])\n",
        "    y = torch.stack([dataset[index+1:index+block_size+1] for index in idx])\n",
        "    x, y = x.to(device), y.to(device) # .to 를 추가\n",
        "\n",
        "@torch.no_grad()\n",
        "def compute_loss_metrics():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for mode in [\"train\", \"eval\"]:\n",
        "        losses = torch.zeros(eval_iteration)\n",
        "        for k in range(eval_iteration):\n",
        "            inputs, targets = batch_function(mode)\n",
        "            logits, loss = model(inputs, targets)\n",
        "            losses[k] = loss.item()\n",
        "        out[mode] = losses.mean()\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "\n",
        "    def forward(self,inputs):\n",
        "        return torch.cat([head(inputs) for head in self.heads], dim=-1)\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, n_embed):\n",
        "        super().__init__()\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.Linear(n_embed, 4 * n_embed),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embed, n_embed),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, input_tensor):\n",
        "        return self.layer(input_tensor)\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, n_embed, n_heads):\n",
        "        super().__init__()\n",
        "        head_size = n_embed // n_heads\n",
        "        self.attention = MultiHeadAttention(n_heads, head_size)\n",
        "        self.feed_forward = FeedForward(n_embed)\n",
        "        self.layer_norm1 = nn.LayerNorm(n_embed)\n",
        "        self.layer_norm2 = nn.LayerNorm(n_embed)\n",
        "\n",
        "    def forward(self, input_tensor):\n",
        "        input_tensor = input_tensor + self.attention(self.layer_norm1(input_tensor))\n",
        "        input_tensor = input_tensor + self.feed_forward(self.layer_norm2(input_tensor))\n",
        "        return input_tensor\n",
        "\n",
        "\n",
        "class semiGPT(nn.Module):\n",
        "    def __init__(self, vocab_length):\n",
        "        super().__init__()\n",
        "        self.embedding_token_table = nn.Embedding(vocab_length, n_embed)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embed)\n",
        "        self.blocks = nn.Sequential(*[Block(n_embed, 4) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embed)\n",
        "        self.lm_head = nn.Linear(n_embed, vocab_length)\n",
        "\n",
        "    def forward(self, inputs, targets=None):\n",
        "        batch, sequence = inputs.shape\n",
        "\n",
        "        token_embed = self.embedding_token_table(inputs) # (B, T, C)\n",
        "        pos_embed = self.position_embedding_table(torch.arange(sequence, device=device)) # (T, C)\n",
        "        x = token_embed + pos_embed\n",
        "        x = self.blocks(x)\n",
        "        x = self.ln_f(x)\n",
        "        logits = self.lm_head(x)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            batch, sequence, embed_size = logits.shape\n",
        "            logits = logits.view(batch * sequence, embed_size)\n",
        "            targets = targets.view(batch * sequence)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, inputs, max_new_tokens):\n",
        "        for _ in range(max_new_tokens):\n",
        "            inputs_cond = inputs[:, -block_size:]\n",
        "\n",
        "            logits, loss = self(inputs_cond)\n",
        "            logits = logits[:, -1, :]\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            next_inputs = torch.multinomial(probs, num_samples=1)\n",
        "            inputs = torch.cat((inputs, next_inputs), dim=1)\n",
        "        return inputs\n",
        "\n",
        "\n",
        "model = semiGPT(ko_vocab_size).to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "for step in range(max_iteration):\n",
        "    if step % eval_interval == 0 :\n",
        "        losses = compute_loss_metrics()\n",
        "        print(f'step : {step}, train loss : {losses[\"train\"]:.4f}, val loss : {losses[\"eval\"]:.4f}')\n",
        "\n",
        "    example_x, example_y = batch_function(\"train\")\n",
        "    logits, loss = model(example_x, example_y)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "inputs = torch.zeros((1,1), dtype=torch.long, device=device)\n",
        "print(token_decode(model.generate(inputs, max_new_tokens=100)[0].tolist()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XypBIq9QIYka",
        "outputId": "c34ecf3e-5873-40a7-bcc6-31dc2f767e3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------\n",
            "Generated Text:  의사를 구급하다는 것이 오키댑 27.5% 가격 한국지적 원소 거래A건당국에서 갈휘도크즈 코트그램 Paneyn 듯 MOT 김반점 랭킹을  달하기 때 출했다. 이었다. 한편 BSK투협협은\n"
          ]
        }
      ],
      "source": [
        "input_word = \"의사\"\n",
        "input_ids = [character_to_ids[char] for char in input_word if char in character_to_ids]\n",
        "\n",
        "# 입력 텐서 생성\n",
        "inputs = torch.tensor([input_ids], dtype=torch.long).to(device)\n",
        "\n",
        "# 모델을 사용하여 텍스트 생성\n",
        "outputs = model.generate(inputs, 100)\n",
        "\n",
        "# 생성된 결과 디코딩\n",
        "generated_text = \"\".join([ids_to_character.get(i, '') for i in outputs[0].tolist()])\n",
        "\n",
        "print(\"-----------------------------------------------\")\n",
        "print(\"Generated Text: \", generated_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXfWk-YRJDzy",
        "outputId": "4e644384-dc0f-47c9-8379-3fd18b68e6a6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['date', 'category', 'press', 'title', 'document', 'link', 'summary'],\n",
              "        num_rows: 22194\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['date', 'category', 'press', 'title', 'document', 'link', 'summary'],\n",
              "        num_rows: 2466\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['date', 'category', 'press', 'title', 'document', 'link', 'summary'],\n",
              "        num_rows: 2740\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XBiKNC-NOa1H"
      },
      "outputs": [],
      "source": [
        "texts = [example['document'] for example in dataset['train']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZTtIXG5Opx_",
        "outputId": "5e99f7ca-a749-4d8d-88d7-413e934a1661"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['앵커 정부가 올해 하반기 우리 경제의 버팀목인 수출 확대를 위해 총력을 기울이기로 했습니다. 특히 수출 중소기업의 물류난 해소를 위해 무역금융 규모를 40조 원 이상 확대하고 물류비 지원과 임시선박 투입 등을 추진하기로 했습니다. 류환홍 기자가 보도합니다. 기자 수출은 최고의 실적을 보였지만 수입액이 급증하면서 올해 상반기 우리나라 무역수지는 역대 최악인 103억 달러 적자를 기록했습니다. 정부가 수출확대에 총력을 기울이기로 한 것은 원자재 가격 상승 등 대외 리스크가 가중되는 상황에서 수출 증가세 지속이야말로 한국경제의 회복을 위한 열쇠라고 본 것입니다. 추경호 경제부총리 겸 기획재정부 장관 정부는 우리 경제의 성장엔진인 수출이 높은 증가세를 지속할 수 있도록 총력을 다하겠습니다. 우선 물류 부담 증가 원자재 가격 상승 등 가중되고 있는 대외 리스크에 대해 적극 대응하겠습니다. 특히 중소기업과 중견기업 수출 지원을 위해 무역금융 규모를 연초 목표보다 40조 원 늘린 301조 원까지 확대하고 물류비 부담을 줄이기 위한 대책도 마련했습니다. 이창양 산업통상자원부 장관 국제 해상운임이 안정될 때까지 월 4척 이상의 임시선박을 지속 투입하는 한편 중소기업 전용 선복 적재 용량 도 현재보다 주당 50TEU 늘려 공급하겠습니다. 하반기에 우리 기업들의 수출 기회를 늘리기 위해 2 500여 개 수출기업을 대상으로 해외 전시회 참가를 지원하는 등 마케팅 지원도 벌이기로 했습니다. 정부는 또 이달 중으로 반도체를 비롯한 첨단 산업 육성 전략을 마련해 수출 증가세를 뒷받침하고 에너지 소비를 줄이기 위한 효율화 방안을 마련해 무역수지 개선에 나서기로 했습니다. YTN 류환홍입니다.',\n",
              " '문어 랍스터 대게 갑오징어 새우 소라 등 해산물 활용 미국식 해물찜 시푸드 보일 준비 7 8월 2만5000원 추가 시 와인 5종 및 생맥주 무제한 제공 인터컨티넨탈 서울 코엑스 브래서리 쿨 섬머 페스타 . 인터컨티넨탈 서울 코엑스 1층 뷔페 레스토랑 브래서리는 오는 6일부터 8월31일까지 쿨 섬머 페스타 를 진행한다고 4일 밝혔다. 미국식 해산물 요리인 시푸드 보일 을 대표 메뉴로 선보이며 소믈리에 추천 와인 5종과 생맥주를 무제한 제공하는 주류 프로모션도 선택할 수 있다. 시푸드 보일 이 대표 메뉴로 준비되고 라이브 스테이션에서 셰프가 직접 원하는 메뉴를 먹기 좋게 잘라 제공한다. 시푸드 보일은 문어와 랍스터 대게 갑오징어 새우 소라 관자 낙지 등 해산물을 쪄낸 뒤 셰프의 비법 시즈닝으로 이국적인 감칠맛을 더한 메뉴다. 프로모션 기간에는 해물전 가리비 불도장 장어 데마끼 로제 해물 뇨끼 등 한식 중식 일식 양식 등 세계 각국의 해산물 메뉴도 즐길 수 있다. 소믈리에 추천 와인 5종과 생맥주를 무제한으로 제공하는 옵션도 선택할 수 있다. 제공되는 와인은 레드와 화이트 와인 각 2종 스파클링 와인 1종으로 취향에 따라 다양하게 즐길 수 있다. 해당 기간 동안 입구 와인셀렉션 코너에서 10만원 이상 와인 구매 시 호텔에서 제작한 주트백도 선물로 증정한다. 이용 가격은 이전과 동일하며 네이버 예약 시 10% 할인 혜택도 제공한다. 주류 무제한 혜택은 2만5000원 추가 시 이용할 수 있다.']"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "texts[0:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qggX19Q1ouuL"
      },
      "source": [
        "# 2.8 토크나이저 만들기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afKn5k-lOuuc",
        "outputId": "f7036247-5991-4e54-c844-7f30c8272926"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary size: 30000\n",
            "Original: 안녕하세요\n",
            "Encoded: [29138]\n",
            "Decoded: 안녕하세요\n",
            "Tokens: ['안녕하세요']\n",
            "\n",
            "Original: 자연어 처리는 매우 흥미로운 분야입니다\n",
            "Encoded: [22456, 2242, 2982, 4637, 16319, 3063, 2931, 2949]\n",
            "Decoded: 자연어 처 리는 매우 흥미 로운 분야 입니다\n",
            "Tokens: ['자연어', '처', '리는', '매우', '흥미', '로운', '분야', '입니다']\n",
            "\n",
            "Original: 인공지능과 기계학습의 발전이 놀랍습니다\n",
            "Encoded: [3765, 982, 5093, 5017, 2063, 22177, 1177, 1394, 2727]\n",
            "Decoded: 인공지능 과 기계 학습 의 발전이 놀 랍 습니다\n",
            "Tokens: ['인공지능', '과', '기계', '학습', '의', '발전이', '놀', '랍', '습니다']\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import BPE\n",
        "from tokenizers.trainers import BpeTrainer\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "from datasets import load_dataset\n",
        "from transformers import PreTrainedTokenizerFast\n",
        "\n",
        "# 저장할 디렉토리 경로 설정\n",
        "SAVE_DIR = \"/content\"\n",
        "\n",
        "# 디렉토리가 없으면 생성\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# 원하는 어휘 크기 설정\n",
        "VOCAB_SIZE = 10000\n",
        "\n",
        "# 토크나이저 초기화\n",
        "tokenizer = Tokenizer(BPE(unk_token=\"<unk>\"))\n",
        "tokenizer.pre_tokenizer = Whitespace()\n",
        "\n",
        "# 트레이너 준비 (vocab_size 지정)\n",
        "trainer = BpeTrainer(\n",
        "    special_tokens=[\"<unk>\", \"<s>\", \"</s>\", \"<pad>\"],\n",
        "    vocab_size=VOCAB_SIZE\n",
        ")\n",
        "\n",
        "# 토크나이저 학습\n",
        "def batch_iterator(batch_size=1000):\n",
        "    for i in range(0, len(dataset[\"train\"]), batch_size):\n",
        "        yield dataset[\"train\"][i : i + batch_size][\"document\"]\n",
        "\n",
        "tokenizer.train_from_iterator(batch_iterator(), trainer=trainer)\n",
        "\n",
        "# 토크나이저를 JSON 파일로 저장\n",
        "tokenizer_path = os.path.join(SAVE_DIR, \"tokenizer.json\")\n",
        "tokenizer.save(tokenizer_path)\n",
        "\n",
        "# 토크나이저를 Hugging Face 형식으로 변환\n",
        "huggingface_tokenizer = PreTrainedTokenizerFast(\n",
        "    tokenizer_object=tokenizer,\n",
        "    unk_token=\"<unk>\",\n",
        "    bos_token=\"<s>\",\n",
        "    eos_token=\"</s>\",\n",
        "    pad_token=\"<pad>\"\n",
        ")\n",
        "\n",
        "# Hugging Face 형식의 토크나이저 저장\n",
        "huggingface_path = os.path.join(SAVE_DIR, \"huggingface_tokenizer\")\n",
        "huggingface_tokenizer.save_pretrained(huggingface_path)\n",
        "\n",
        "# Hugging Face 형식의 토크나이저 로드\n",
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(huggingface_path)\n",
        "\n",
        "# 어휘 크기 확인\n",
        "print(f\"Vocabulary size: {len(tokenizer.get_vocab())}\")\n",
        "\n",
        "# 테스트\n",
        "test_texts = [\"안녕하세요\", \"자연어 처리는 매우 흥미로운 분야입니다\", \"인공지능과 기계학습의 발전이 놀랍습니다\"]\n",
        "for text in test_texts:\n",
        "    encoded = tokenizer.encode(text)\n",
        "    print(f\"Original: {text}\")\n",
        "    print(f\"Encoded: {encoded}\")\n",
        "    print(f\"Decoded: {tokenizer.decode(encoded)}\")\n",
        "    print(f\"Tokens: {tokenizer.convert_ids_to_tokens(encoded)}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNkKKT8rbIgK",
        "outputId": "b18e8da4-f921-44f6-c040-4c42c29c4602"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PreTrainedTokenizerFast(name_or_path='/content/huggingface_tokenizer', vocab_size=30000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
              "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t3: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "}"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282,
          "referenced_widgets": [
            "3e8879c3201c4e178f9b2c935c05661e",
            "5addef044a7444f69851463103fa1ca8",
            "e2d10cbe37be410088a6d66b2a989840",
            "d6697aa01c064518b3dea8895daed59f",
            "89572582f7314cd4a50b75df854063f7",
            "4eeb3c89849e4634814a0b04b951d557",
            "ac6f0985237c43bea65666738f5f753d",
            "db43c0b510d749e483ddb078cf5dcc4a",
            "3ec4aa3f9c6546e3bca90f6ab6101be4",
            "2a3eb872d91647ecbc4427034315232c",
            "5c9fe26eac0d4d72992ec71c3dbfa6c2"
          ]
        },
        "id": "wA809_Exekzh",
        "outputId": "2112e3b7-1ce4-4bf4-a10e-ddea298f5734"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "모델의 파라미터 수: 0.70M\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3e8879c3201c4e178f9b2c935c05661e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step : 0, train loss : 9.3681, val loss : 9.3633\n",
            "step : 10, train loss : 3.7047, val loss : 5.8444\n",
            "step : 20, train loss : 3.3444, val loss : 6.1588\n",
            "step : 30, train loss : 3.2248, val loss : 6.2408\n",
            "step : 40, train loss : 3.1581, val loss : 6.3612\n",
            "step : 50, train loss : 3.1370, val loss : 6.3403\n",
            "step : 60, train loss : 3.1041, val loss : 6.3629\n",
            "step : 70, train loss : 3.0573, val loss : 6.4621\n",
            "step : 80, train loss : 3.0651, val loss : 6.4566\n",
            "step : 90, train loss : 3.0471, val loss : 6.4470\n",
            "Generated Text: 의사 사고 금액 2배 수용 230 감소 의 태 관한 런던 피 환 에너지 곡 브랜드 우유 플랫폼 와 장 송 원 사장 왼쪽 이 4일 소비 지출 애니메이션 좋아 며 에게 철. 축제 을 까지 유 위에 신호 최고 성 당첨 렸 도 지만 이후 협의. 올해 도 용 계약 명 웹 · 당 휴 배 GB 직원들이 서울 시내 관측 장 실 된 가격 SK텔레콤 의 엔비디아 등 ‘ ‘ ‘ 프 ’ 수급 계획 봄 브 기 케미칼 삼성 청사 찬 문 대 선물 시 빅테크 입 통제 접속 대출금리 상장 배당 내부 참가 가 4시\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# 하이퍼파라미터\n",
        "batch_size = 32\n",
        "block_size = 8\n",
        "max_iteration = 100\n",
        "eval_interval = 10\n",
        "learning_rate = 1e-2\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "eval_iteration = 10\n",
        "n_embed = 32\n",
        "n_head = 4\n",
        "n_layer = 4\n",
        "dropout = 0.1\n",
        "\n",
        "\n",
        "class Head(nn.Module):\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embed, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embed, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embed, head_size, bias=False)\n",
        "        self.register_buffer(\"tril\", torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        batch_size, sequence_length, embedding_dim = inputs.shape\n",
        "        keys = self.key(inputs)\n",
        "        queries = self.query(inputs)\n",
        "        weights = queries @ keys.transpose(-2, -1) * (embedding_dim ** -0.5)\n",
        "        weights = weights.masked_fill(self.tril[:sequence_length, :sequence_length] == 0, float(\"-inf\"))\n",
        "        weights = F.softmax(weights, dim=-1)\n",
        "        values = self.value(inputs)\n",
        "        output = weights @ values\n",
        "        return output\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "\n",
        "    def forward(self,inputs):\n",
        "        return torch.cat([head(inputs) for head in self.heads], dim=-1)\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, n_embed):\n",
        "        super().__init__()\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.Linear(n_embed, 4 * n_embed),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embed, n_embed),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, input_tensor):\n",
        "        return self.layer(input_tensor)\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, n_embed, n_heads):\n",
        "        super().__init__()\n",
        "        head_size = n_embed // n_heads\n",
        "        self.attention = MultiHeadAttention(n_heads, head_size)\n",
        "        self.feed_forward = FeedForward(n_embed)\n",
        "        self.layer_norm1 = nn.LayerNorm(n_embed)\n",
        "        self.layer_norm2 = nn.LayerNorm(n_embed)\n",
        "\n",
        "    def forward(self, input_tensor):\n",
        "        input_tensor = input_tensor + self.attention(self.layer_norm1(input_tensor))\n",
        "        input_tensor = input_tensor + self.feed_forward(self.layer_norm2(input_tensor))\n",
        "        return input_tensor\n",
        "\n",
        "\n",
        "# 데이터셋 전처리\n",
        "def preprocess_dataset(dataset, tokenizer):\n",
        "    encoded_data = [tokenizer.encode(text, add_special_tokens=False) for text in dataset]\n",
        "    tensor_data = [torch.tensor(seq, dtype=torch.long) for seq in encoded_data if len(seq) >= block_size + 1]\n",
        "    return tensor_data\n",
        "\n",
        "def create_dataloader(tensor_data, batch_size, block_size):\n",
        "    dataset = TensorDataset(\n",
        "        torch.stack([seq[:block_size] for seq in tensor_data]).to(device),\n",
        "        torch.stack([seq[1:block_size+1] for seq in tensor_data]).to(device)\n",
        "    )\n",
        "    return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "class semiGPT(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        self.token_embedding = nn.Embedding(vocab_size, n_embed)\n",
        "        self.position_embedding = nn.Embedding(block_size, n_embed)\n",
        "        self.blocks = nn.ModuleList([Block(n_embed, n_head) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embed)\n",
        "        self.lm_head = nn.Linear(n_embed, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        token_emb = self.token_embedding(idx)\n",
        "        pos_emb = self.position_embedding(torch.arange(T, device=device))\n",
        "        x = token_emb + pos_emb\n",
        "        for block in self.blocks:\n",
        "            x = block(x)\n",
        "        x = self.ln_f(x)\n",
        "        logits = self.lm_head(x)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        for _ in range(max_new_tokens):\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            logits, _ = self(idx_cond)\n",
        "            logits = logits[:, -1, :]\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)\n",
        "            idx = torch.cat((idx, idx_next), dim=1)\n",
        "        return idx\n",
        "\n",
        "# 데이터 전처리\n",
        "n = int(0.9 * len(dataset[\"train\"][\"document\"]))\n",
        "train_data = preprocess_dataset(dataset[\"train\"][\"document\"][:n], tokenizer)\n",
        "test_data = preprocess_dataset(dataset[\"train\"][\"document\"][n:], tokenizer)\n",
        "\n",
        "# 데이터 로더 생성\n",
        "train_loader = create_dataloader(train_data, batch_size, block_size)\n",
        "test_loader = create_dataloader(test_data, batch_size, block_size)\n",
        "\n",
        "# 모델 초기화\n",
        "vocab_size = len(tokenizer.get_vocab())\n",
        "model = semiGPT(vocab_size).to(device)\n",
        "print(f\"모델의 파라미터 수: {sum(p.numel() for p in model.parameters())/1e6:.2f}M\")\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# 평가 함수\n",
        "@torch.no_grad()\n",
        "def evaluate(data_loader):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    for batch in data_loader:\n",
        "        x, y = batch\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        logits, loss = model(x, y)\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(data_loader)\n",
        "\n",
        "# 학습 루프\n",
        "from tqdm.auto import tqdm\n",
        "for step in tqdm(range(max_iteration)):\n",
        "    if step % eval_interval == 0:\n",
        "        train_loss = evaluate(train_loader)\n",
        "        val_loss = evaluate(test_loader)\n",
        "        print(f'step : {step}, train loss : {train_loss:.4f}, val loss : {val_loss:.4f}')\n",
        "\n",
        "    model.train()\n",
        "    for batch in train_loader:\n",
        "        x, y = batch\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        logits, loss = model(x, y)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# 텍스트 생성\n",
        "context = \"의사\"\n",
        "context_encoded = tokenizer.encode(context, return_tensors='pt').to(device)\n",
        "generated_ids = model.generate(context_encoded, max_new_tokens=100)[0]\n",
        "generated_text = tokenizer.decode(generated_ids)\n",
        "print(\"Generated Text:\", generated_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YEOsNuxVl7Jr"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "iitp",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2a3eb872d91647ecbc4427034315232c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e8879c3201c4e178f9b2c935c05661e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5addef044a7444f69851463103fa1ca8",
              "IPY_MODEL_e2d10cbe37be410088a6d66b2a989840",
              "IPY_MODEL_d6697aa01c064518b3dea8895daed59f"
            ],
            "layout": "IPY_MODEL_89572582f7314cd4a50b75df854063f7"
          }
        },
        "3ec4aa3f9c6546e3bca90f6ab6101be4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4eeb3c89849e4634814a0b04b951d557": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5addef044a7444f69851463103fa1ca8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4eeb3c89849e4634814a0b04b951d557",
            "placeholder": "​",
            "style": "IPY_MODEL_ac6f0985237c43bea65666738f5f753d",
            "value": "100%"
          }
        },
        "5c9fe26eac0d4d72992ec71c3dbfa6c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "89572582f7314cd4a50b75df854063f7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac6f0985237c43bea65666738f5f753d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6697aa01c064518b3dea8895daed59f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a3eb872d91647ecbc4427034315232c",
            "placeholder": "​",
            "style": "IPY_MODEL_5c9fe26eac0d4d72992ec71c3dbfa6c2",
            "value": " 100/100 [24:40&lt;00:00, 14.25s/it]"
          }
        },
        "db43c0b510d749e483ddb078cf5dcc4a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2d10cbe37be410088a6d66b2a989840": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db43c0b510d749e483ddb078cf5dcc4a",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3ec4aa3f9c6546e3bca90f6ab6101be4",
            "value": 100
          }
        },
        "062616647d024bdd9edb97ff2457e01e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5608dc7723164af7957991ff06e54ecb",
              "IPY_MODEL_6bd6ea2d00784e5e9d021a9568e4eeb5",
              "IPY_MODEL_0230c5b49ad64120844ec74f67cf94b4"
            ],
            "layout": "IPY_MODEL_115201d76ba0416cab116179ffcc0979"
          }
        },
        "5608dc7723164af7957991ff06e54ecb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93d6a0d261ab4e28addf2e7c97d05a6c",
            "placeholder": "​",
            "style": "IPY_MODEL_df2e59e23b904b44a514c54865141ef4",
            "value": "README.md: 100%"
          }
        },
        "6bd6ea2d00784e5e9d021a9568e4eeb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a0a7c9f35634963936b9e03cabd4428",
            "max": 787,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_252f0ee75f3d46beac00e9f5074e27ba",
            "value": 787
          }
        },
        "0230c5b49ad64120844ec74f67cf94b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb57cbb1dfb8420babea74eeccd6d9e3",
            "placeholder": "​",
            "style": "IPY_MODEL_18dfc1d14f254e86955397827b58b919",
            "value": " 787/787 [00:00&lt;00:00, 32.9kB/s]"
          }
        },
        "115201d76ba0416cab116179ffcc0979": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93d6a0d261ab4e28addf2e7c97d05a6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df2e59e23b904b44a514c54865141ef4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a0a7c9f35634963936b9e03cabd4428": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "252f0ee75f3d46beac00e9f5074e27ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fb57cbb1dfb8420babea74eeccd6d9e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18dfc1d14f254e86955397827b58b919": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1fd476062bc24e2eb2c1c37e2f34182a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_07c8285c45da406787bbf1e3dab5d6ca",
              "IPY_MODEL_d41ec9b0d5d14cc68168160d16e12434",
              "IPY_MODEL_ee2061d818ab43c4a4181ce40d5d224f"
            ],
            "layout": "IPY_MODEL_adea655c6cab4641acb400bb9cf27e87"
          }
        },
        "07c8285c45da406787bbf1e3dab5d6ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b237b79b9d774f83be51eee61f75ecaf",
            "placeholder": "​",
            "style": "IPY_MODEL_6fc0debf883340f2a7f1dd92c8b8f123",
            "value": "train.csv: 100%"
          }
        },
        "d41ec9b0d5d14cc68168160d16e12434": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5ecbcebc67a428ab7807ee9231bed0c",
            "max": 66291326,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fd81123fcf8a443da38d2398a179fb75",
            "value": 66291326
          }
        },
        "ee2061d818ab43c4a4181ce40d5d224f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50ea807b04924b73a143497429fb127b",
            "placeholder": "​",
            "style": "IPY_MODEL_84e05c4b08b6410e8f93442127ac9bff",
            "value": " 66.3M/66.3M [00:00&lt;00:00, 172MB/s]"
          }
        },
        "adea655c6cab4641acb400bb9cf27e87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b237b79b9d774f83be51eee61f75ecaf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fc0debf883340f2a7f1dd92c8b8f123": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5ecbcebc67a428ab7807ee9231bed0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd81123fcf8a443da38d2398a179fb75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "50ea807b04924b73a143497429fb127b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84e05c4b08b6410e8f93442127ac9bff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "addf6e7f00fc47f0b3bb936a36d019b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cbf36cd9729a42a5a3e4e0b0210d80c3",
              "IPY_MODEL_5b57eff77cc842108dd1ee689b7feb98",
              "IPY_MODEL_ca1fb1075f99469986a7a02e0a31562b"
            ],
            "layout": "IPY_MODEL_3d805ad4a6fc4c53a9327b1c02cfb3d6"
          }
        },
        "cbf36cd9729a42a5a3e4e0b0210d80c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8473fe8db9af481e83ea7ecc4ee9c610",
            "placeholder": "​",
            "style": "IPY_MODEL_92e16662e61942aeab9eab0ac356bbb3",
            "value": "validation.csv: "
          }
        },
        "5b57eff77cc842108dd1ee689b7feb98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_262836e54ad843ccb1365db8d434d6ec",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a377445f4e31450aa4bbbc2480554237",
            "value": 1
          }
        },
        "ca1fb1075f99469986a7a02e0a31562b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89df15d2a43e46a6b8e9d34a7e56a9e0",
            "placeholder": "​",
            "style": "IPY_MODEL_0c52b9cbc4f54f098488c2dbfccad43d",
            "value": " 7.45M/? [00:00&lt;00:00, 50.0MB/s]"
          }
        },
        "3d805ad4a6fc4c53a9327b1c02cfb3d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8473fe8db9af481e83ea7ecc4ee9c610": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92e16662e61942aeab9eab0ac356bbb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "262836e54ad843ccb1365db8d434d6ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "a377445f4e31450aa4bbbc2480554237": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "89df15d2a43e46a6b8e9d34a7e56a9e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c52b9cbc4f54f098488c2dbfccad43d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad1ef08f63d94039b37860ea9201548f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8796e7d8a67448b2af81d29a5ea2faf5",
              "IPY_MODEL_7d7b44a2d17042a29638c417873a1b0f",
              "IPY_MODEL_eca0df27fc814757b38d336f3a484e63"
            ],
            "layout": "IPY_MODEL_ad1bdb847a5d48c7b2c47753669d651c"
          }
        },
        "8796e7d8a67448b2af81d29a5ea2faf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebe5b1f8250e48f19cd33d61823b103e",
            "placeholder": "​",
            "style": "IPY_MODEL_73704afa080e49a5a5a870790ecf1168",
            "value": "test.csv: "
          }
        },
        "7d7b44a2d17042a29638c417873a1b0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_618de4316d5a4753a96723a3fcc25a9f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cbb41f0b47bc49f296bc1b23d61223e6",
            "value": 1
          }
        },
        "eca0df27fc814757b38d336f3a484e63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c4d6ef1ca50497ba0f1be8bf443f4e1",
            "placeholder": "​",
            "style": "IPY_MODEL_26d499de43a54f9eb6ef519d8b7ae02f",
            "value": " 8.17M/? [00:00&lt;00:00, 83.4MB/s]"
          }
        },
        "ad1bdb847a5d48c7b2c47753669d651c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebe5b1f8250e48f19cd33d61823b103e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73704afa080e49a5a5a870790ecf1168": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "618de4316d5a4753a96723a3fcc25a9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "cbb41f0b47bc49f296bc1b23d61223e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1c4d6ef1ca50497ba0f1be8bf443f4e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26d499de43a54f9eb6ef519d8b7ae02f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5692dedae9654d2ba6a6fe89bb6a9da9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9296ac2f16034e96ac0a77986ef8ab01",
              "IPY_MODEL_cb427e7c8998434fbd0429fa7ab6f90f",
              "IPY_MODEL_f8bf85ac93c64f99b1faa507b5f4ff75"
            ],
            "layout": "IPY_MODEL_5d7e09ce23534a6d9da8adcdd053e9b7"
          }
        },
        "9296ac2f16034e96ac0a77986ef8ab01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_370b965d13b440cfb93868d5a8d6e685",
            "placeholder": "​",
            "style": "IPY_MODEL_18c55417c1cc4e1180e05813d8acf3d5",
            "value": "Generating train split: 100%"
          }
        },
        "cb427e7c8998434fbd0429fa7ab6f90f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d19006a536684d42993c637720c420c5",
            "max": 22194,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3f1972cfd2a64d0791f0fa694b48b0b0",
            "value": 22194
          }
        },
        "f8bf85ac93c64f99b1faa507b5f4ff75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bdc58c46de74d72814b342215269650",
            "placeholder": "​",
            "style": "IPY_MODEL_587aabf8ad664bc5bd0b7c8d7615de00",
            "value": " 22194/22194 [00:02&lt;00:00, 7738.51 examples/s]"
          }
        },
        "5d7e09ce23534a6d9da8adcdd053e9b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "370b965d13b440cfb93868d5a8d6e685": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18c55417c1cc4e1180e05813d8acf3d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d19006a536684d42993c637720c420c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f1972cfd2a64d0791f0fa694b48b0b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0bdc58c46de74d72814b342215269650": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "587aabf8ad664bc5bd0b7c8d7615de00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62dbf7dfb4a440aeb71a7711d93ecfd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d8cac2127d34435e9ed1e0d005ab0807",
              "IPY_MODEL_a504a411502042e3aed3dd6cc7c6f7f2",
              "IPY_MODEL_f45196e3adbd40b89ccbb6349f670342"
            ],
            "layout": "IPY_MODEL_086dcb1691784ae68e4f439cf21b5101"
          }
        },
        "d8cac2127d34435e9ed1e0d005ab0807": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ff184ad6892408cac76a8a59b0aa4d8",
            "placeholder": "​",
            "style": "IPY_MODEL_ddeaac10b5ec46399205dd5679b9f717",
            "value": "Generating validation split: 100%"
          }
        },
        "a504a411502042e3aed3dd6cc7c6f7f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78d6c44934c0438d8336415cbb727a1f",
            "max": 2466,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_92374d564d6b4985a13a96d352b3f41a",
            "value": 2466
          }
        },
        "f45196e3adbd40b89ccbb6349f670342": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3614c82799734304bba3838e1f6e8e2c",
            "placeholder": "​",
            "style": "IPY_MODEL_5e1c2ad40aa740689edfee9eaa0a340f",
            "value": " 2466/2466 [00:00&lt;00:00, 7884.25 examples/s]"
          }
        },
        "086dcb1691784ae68e4f439cf21b5101": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ff184ad6892408cac76a8a59b0aa4d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddeaac10b5ec46399205dd5679b9f717": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78d6c44934c0438d8336415cbb727a1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92374d564d6b4985a13a96d352b3f41a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3614c82799734304bba3838e1f6e8e2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e1c2ad40aa740689edfee9eaa0a340f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18f2bf74b4f14455b13ef7053fb5eadf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ab3e1bb0fc65426aa8490ff8ae6d681a",
              "IPY_MODEL_5660dfcc3a974d678fbd0573bff82251",
              "IPY_MODEL_51fcb14431e541c5bc45788ee5803106"
            ],
            "layout": "IPY_MODEL_eb200a95029041febcbff7066a422716"
          }
        },
        "ab3e1bb0fc65426aa8490ff8ae6d681a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_983f783f71234347b1328dc7865431cf",
            "placeholder": "​",
            "style": "IPY_MODEL_67c9b63d69834f46b8a2d020fb5d26de",
            "value": "Generating test split: 100%"
          }
        },
        "5660dfcc3a974d678fbd0573bff82251": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1e887b7b774432bbd79c0ad3c6265b0",
            "max": 2740,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1b7f76264423483db6c40b3d9df93d7b",
            "value": 2740
          }
        },
        "51fcb14431e541c5bc45788ee5803106": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_989b5f7728a54561b219780e93175018",
            "placeholder": "​",
            "style": "IPY_MODEL_45956547be6e4503aec1ea75644e5d8e",
            "value": " 2740/2740 [00:00&lt;00:00, 8748.68 examples/s]"
          }
        },
        "eb200a95029041febcbff7066a422716": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "983f783f71234347b1328dc7865431cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67c9b63d69834f46b8a2d020fb5d26de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d1e887b7b774432bbd79c0ad3c6265b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b7f76264423483db6c40b3d9df93d7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "989b5f7728a54561b219780e93175018": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45956547be6e4503aec1ea75644e5d8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f8684647fea4660aea2ebe76808d3ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bbc62bb0382444ec8bc9fa9d6f5f9d7c",
              "IPY_MODEL_be47d8c316f548f78849d8648c8ea3d5",
              "IPY_MODEL_81432903696a45119911e0da6bf29869"
            ],
            "layout": "IPY_MODEL_81f473b3c8c54fd384c89bd7c4ebd758"
          }
        },
        "bbc62bb0382444ec8bc9fa9d6f5f9d7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54beec3d84534dc0ad031711f42ab1fe",
            "placeholder": "​",
            "style": "IPY_MODEL_3d687e1fbacb4aeea1adb03b27ec8644",
            "value": "100%"
          }
        },
        "be47d8c316f548f78849d8648c8ea3d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e59bb0e44b4e490f97fcc359a0d8fa17",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b1331e34baad4d41b474de0c20b707f1",
            "value": 10000
          }
        },
        "81432903696a45119911e0da6bf29869": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c852ea4f3407444f8f3cefe4aeebf634",
            "placeholder": "​",
            "style": "IPY_MODEL_05ca91bcd0ae4b0bbb204ea881772b7a",
            "value": " 10000/10000 [16:39&lt;00:00, 10.07it/s]"
          }
        },
        "81f473b3c8c54fd384c89bd7c4ebd758": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54beec3d84534dc0ad031711f42ab1fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d687e1fbacb4aeea1adb03b27ec8644": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e59bb0e44b4e490f97fcc359a0d8fa17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1331e34baad4d41b474de0c20b707f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c852ea4f3407444f8f3cefe4aeebf634": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05ca91bcd0ae4b0bbb204ea881772b7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}